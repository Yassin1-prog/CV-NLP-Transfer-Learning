{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rdxpox811Zjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "caa50cc0-7c94-45c9-e5e5-4a50b9ab9a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m754.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets\n",
        "! pip install evaluate\n",
        "! pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Προσοχή\n",
        "\n",
        "Μη διαγράψετε τα # insert your code here σχόλια, καθώς βοηθούν στη διόρθωση. Συμπληρώστε τον κώδικά σας μετά από τα σχόλια αυτά."
      ],
      "metadata": {
        "id": "iJDLl00oIl-k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc_H7oqS1Zjz"
      },
      "source": [
        "# Μέρος Α: Fine-tune a pretrained model\n",
        "\n",
        "Τα γλωσσικά μοντέλα αποτελούνται από δύο στάδια εκπαίδευσης:\n",
        "1. **Pre-training σε μεγάλα unlabelled datasets**:\n",
        "\n",
        "  Το pre-training είναι υπολογιστικά πολύ ακριβό και γι αυτό στην πράξη δε το χρησιμοποιούμε όταν θέλουμε να τρέξουμε ένα μοντέλο σε ένα καινούργιο dataset. Μπορούμε να σκεφτούμε το pre-training ως τη διαδικασία εκμάθησης γλωσσικών κανόνων κι εννοιών, οι οποίες στη συνέχεια μπορούν να χρησιμοποιηθούν για διάφορους σκοπούς.\n",
        "\n",
        "2. **Fine-tuning σε μικρότερα labelled datasets**:\n",
        "  \n",
        "     Το fine-tuning πρακτικά εκμεταλλεύεται τις ιδιότητες του transfer learning προκειμένου να μεταφέρουμε τη 'γνώση' που έχει αποθηκευθεί στο γλωσσικό μοντέλο κατά τη διάρκεια του pre-training σε συγκεκριμένα task. Κάθε task εξυπηρετείται μέσω στοχευμένων datasets. Για παράδειγμα, κάποια datasets αναφέρονται στην ταξινόμηση κειμένων σε κατηγιορίες (text classification), άλλα datasets περιέχουν ερωτήσεις οι οποίες πρέπει να απαντηθούν (question answering) κι άλλα πολλά.\n",
        "\n",
        "Κάποια κλασικά tasks της επεξεργασίας φυσικής γλώσσας είναι τα ακόλουθα:\n",
        "- Text classification\n",
        "- Question answering\n",
        "- Natural language inference\n",
        "- Fill mask\n",
        "- Semantic similarity\n",
        "\n",
        "Περισσότερες πληροφορίες μπορείτε να βρείτε στον ακόλουθο σύνδεσμο στο domain Natural Language Processing: https://huggingface.co/models\n",
        "\n",
        "Στο πρώτο κομμάτι της παρούσας εργαστηριακής άσκησης, θα χρησιμοποιήσουμε το pre-training fine-tuning σενάριο για να ταξινομήσουμε reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipelines\n",
        "\n",
        "Με τη χρήση του **text-classification pipeline** μπορούμε να τρέξουμε γλωσσικά μοντέλα που αφορούν tasks ταξινόμησης.\n",
        "\n",
        "Το natural language inference (NLI) task αποτελεί ένα task ταξινόμησης, αφού το σχετικό μοντέλο (εν προκειμένω το roberta-large-mnli) καλείται να ταξινομήσει ένα κείμενο σε μία από τις 3 κατηγορίες: **[entailment/neutral/contradiction]**.\n",
        "\n",
        "```\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model = \"roberta-large-mnli\")\n",
        "classifier(\"A soccer game with multiple males playing. Some men are playing a sport.\")\n",
        "## [{'label': 'ENTAILMENT', 'score': 0.98}]\n",
        "```\n",
        "\n",
        "Ένα άλλο task ταξινόμησης αφορά την αξιολόγηση του κατά πόσο ένα κείμενο είναι **γραμματικά ορθό (acceptable) ή όχι (unacceptable)**:\n",
        "\n",
        "```\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model = \"textattack/distilbert-base-uncased-CoLA\")\n",
        "classifier(\"I will walk to home when I went through the bus.\")\n",
        "##  [{'label': 'unacceptable', 'score': 0.95}]\n",
        "```"
      ],
      "metadata": {
        "id": "4-KvTKunnp0v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2UxEv7x1Zj1"
      },
      "source": [
        "## Σύνολο δεδομένων Yelp polarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTNsahTl1Zj2"
      },
      "source": [
        "Κατεβάζουμε το [Yelp Polarity](https://huggingface.co/datasets/yelp_polarity) dataset το οποίο περιέχει reviews που εκφράζουν συναισθήματα πελατών για εστιατόρια.\n",
        "Το  Yelp κατασκευάστηκε θεωρώντας τα αστέρια 1 και 2 αρνητικά και τα 3 και 4 θετικά.  Η αρνητική πολικότητα ανήκει στην κατηγορία 1 και η θετική στην κατηγορία 2. Τα reviews αυτά χωρίζονται σε αυτές τις κατηγορίες, και ο σκοπός μας είναι να κατηγοριοποιήσουμε νέα reviews στις σωστές κατηγορίες.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# insert your code here\n",
        "\n",
        "reviews = load_dataset('fancyzhx/yelp_polarity')\n",
        "print(reviews)"
      ],
      "metadata": {
        "id": "uS3fgJzzNBQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "8dd0b7c88c3b479c969dd8267436d78f",
            "910b30550ce342248fbc0203ead81d97",
            "dd72942fb13741489036b2be632621c3",
            "61af98ef5f1b43ee838cc484af2d7fb5",
            "a7e552e28606495b95187619edfb432f",
            "7758f815c36c4337b7aacaf507889e79",
            "512a5ce43c00404eaa1daa1477cd46fd",
            "b0c7b37ed61441bc9fe3678a2b98a87c",
            "1856a9d4041a4865960f132d82a0dc05",
            "5bfcadc7695248dbb627fad88f45a533",
            "18c9c551ad0141cfa5137d9bb10c2526",
            "d46d55e353b645d08d7cf9486f5a4ec6",
            "14eb34cb2d0546ceaedb56e878325504",
            "a92790f3e3da4cdb9fcda812694fed9d",
            "d0b66bf19df640db938b96a9aeee6424",
            "3ec5ed7f56804fbdad94b7970eec0440",
            "9573765713cd4ecebd1afe16856c339d",
            "05159419be6f4474b91d421872b50f48",
            "beb2a480e92a4ad1959f3e521691c647",
            "e5ac05ca19ed41d2a12e4cf1e9da1917",
            "163d53c56b88471faf45ec928803a0cf",
            "fdb09ece7d294fd3bf229b906200048d",
            "b02adc890b9343acbc385f1bb2bafff5",
            "094306f5f2dd40f3915b95e7ad6a1ef9",
            "a3cf8f7b0cd040e4aa11ac08408ac388",
            "cb39f43b3ae142d5b5424bcf512eb356",
            "41bf34adb2734f1d92b5a19d0f3546c4",
            "0e8228770b34446e9b16ba73f25e5340",
            "8c3ef2ad543243eba0242cd4e31f1b6b",
            "bcc26039dd864eeeb3e24947dc29a83e",
            "a51a039035dd40558597d96fe8ca7f02",
            "3290e0e400474b2ea0a5b193e08bbb2a",
            "b4e7ec7a844c493e868799c209ea5351",
            "3d985827d7bf4e41956c125661faafc1",
            "42dcc94e091b47249e3de30483263815",
            "2d32a9b77a834fceb2e0838e5ff9c59d",
            "ba645e0bb8ae433b85bd42a9fb9ec691",
            "a0d3394d41b0455e837ca72c617db747",
            "069cf27394ba42528b243c551b48b368",
            "00686f9ebc4947208109756c46ffe552",
            "51d92eecb2b844168a7756c0c3100f69",
            "06cbc4bc5701418e8b753026e4ba96e9",
            "161c50191a424167aef5ced14f6d2417",
            "0e782dc5c6fc4b258d23723574c8f2b4",
            "8d393162139a4868867637620c89d581",
            "19785f94fd7d472c92f7c65faddfa28d",
            "c881a182cb304dd88f5c71e5b23f816b",
            "2cee781a289140c9824cb95391afda6c",
            "b20fe04bd4a346418cec03ccbc757073",
            "eabef3f0d93840f8a4717d80cf01a209",
            "b671907f2d8346cdbfe7ce6b601a3e2f",
            "e715a06853eb40918ea58b7c9139962e",
            "c52c928f5a354fd49dbfcf38894613e1",
            "938c8f5ea8ee4e61815330e092549e7c",
            "3dba227997224a6dabc4dcb0db664f03"
          ]
        },
        "outputId": "29a50a29-d6b2-45c5-b2ce-7978ac0998e5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.93k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dd0b7c88c3b479c969dd8267436d78f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d46d55e353b645d08d7cf9486f5a4ec6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b02adc890b9343acbc385f1bb2bafff5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/560000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d985827d7bf4e41956c125661faafc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/38000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d393162139a4868867637620c89d581"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 560000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 38000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επειδή το σύνολο δεδομένων του Yelp Polarity περιέχει πολλά δείγματα, προκειμένου να επιταχύνουμε τη διαδικασία του fine-tuning συστήνουμε να διατηρήσετε 300 δείγματα από το train set και 300 δείγματα από το test set.\n",
        "\n",
        "Ελέγξτε τον αριθμό κατηγοριών που υπάρχουν συνολικά στο train και το test set και διατηρήστε ισορροπημένο αριθμό δειγμάτων ανά κατηγορία για τα σύνολα αυτά κατά την επιλογή των 300 δειγμάτων."
      ],
      "metadata": {
        "id": "0hEzVNuLWzm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "print(\"Classes:\", reviews['train'].unique('label'))\n",
        "\n",
        "label_counts = collections.Counter(reviews['train']['label'])\n",
        "print(\"Label Counts:\", label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82PB6-UgDNCu",
        "outputId": "ecbafd1d-cc8e-4e36-d5b1-2fb0e8118d1e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: [0, 1]\n",
            "Label Counts: Counter({0: 280000, 1: 280000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here\n",
        "from datasets import concatenate_datasets\n",
        "\n",
        "def subset_data(split):\n",
        "  class_0_samples = reviews[split].filter(lambda example: example['label'] == 0).select(range(150))\n",
        "  class_1_samples = reviews[split].filter(lambda example: example['label'] == 1).select(range(150))\n",
        "  return concatenate_datasets([class_0_samples, class_1_samples]).shuffle(seed=42)"
      ],
      "metadata": {
        "id": "pcLF72ZOxWbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = subset_data('train')\n",
        "eval_dataset = subset_data('test')"
      ],
      "metadata": {
        "id": "R-Kj4N9yMaoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "987fad5733254ba0b1014b43e96f0998",
            "b308e815250942c0beadc2c40a441f1f",
            "3b837ee3976c433ab99aa1167837ac8b",
            "3d44b524ee03430396436d6b345436b2",
            "02c5c5d9b4ed44139d895d910ffb0c29",
            "f51d66290cee45fa9a86a2331a22176b",
            "53313a481118427c8f080941646e2901",
            "e7e8ec6faacb495b82fc98f17dcd9cca",
            "25773c4cf62c44799d7827e18ef5a7aa",
            "a566d1a69aee4085bfb1c714fee2fde2",
            "6263473ef46640728439b9cba605472d",
            "5a546f95f204489db0ce9c0477aac031",
            "4f2d589e73f641fcbc6c2ea514a84b15",
            "77a21e37f67e40a784c66de4115cc478",
            "5b0812493d074cc898d5f47cc06495d3",
            "fff8649dfdfa41588d945ec01218d32b",
            "6b4301fd8fc84e5090baf363c0ffaff4",
            "1628409861fd40778c2aa777fb0f90e0",
            "4dbed832d79d494e8708e5d37f9e00de",
            "893a1c3322274d699984f499342e1acf",
            "5dd1b9809eaf4d4fb1b182735cbe79a3",
            "fd205bdb8baa49d88a4d5d648fc1043b",
            "c501884fdf45438a866092becd8684b1",
            "bfda03f6405e439e9069bdaf76a1ae7b",
            "bf039d5d3f7d451eb9cc3c90f4dac5f4",
            "62b7a69108d646e99db4b6ed7da081a5",
            "e5a05eced83845bd989fd293d286141b",
            "6c39668f5240492e860503ce60bf6ce6",
            "cdeae962c41e453ca33736aba05aa90a",
            "8751cfd0b8f74497a1821381649fd6d2",
            "220832352418417d9f1a741849e7a4cd",
            "e31f00f3cd094cd8a72613a5753d21ba",
            "8dc042fa91594b759fed1a6a9f0a4915",
            "e4a0bcd5816c4003b3e9f667fc172df9",
            "b1c315ad634242868be6e1706f883f1c",
            "e0ca8da3a5e04eb4b9ee1e5cb949a910",
            "7b9debe54f224018ba225393331a4646",
            "b3e9be2645dc4c2d832ac1d03048c193",
            "5ee6f1877e5249bda17c8dc630979751",
            "abc20f7c18c947de85756a6ca35bee27",
            "be9716b9d3f344179e9aa7183609451f",
            "6560dd68641446b7ad1a74a141b08c2c",
            "1498096b1c764558895c99f2fcc3483d",
            "f4b4ac163e284dbca7b3ff8d27f90636"
          ]
        },
        "outputId": "a87b0d6c-7c21-4b66-95a3-436527ef3e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/560000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "987fad5733254ba0b1014b43e96f0998"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/560000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a546f95f204489db0ce9c0477aac031"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/38000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c501884fdf45438a866092becd8684b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/38000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4a0bcd5816c4003b3e9f667fc172df9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Label Counts\", collections.Counter(train_dataset['label']))\n",
        "print(\"Evaluation Label Counts\", collections.Counter(eval_dataset['label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZM9lwlnJR48",
        "outputId": "fa482ac1-1dad-44ce-a803-446174b1f01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Label Counts Counter({1: 150, 0: 150})\n",
            "Evaluation Label Counts Counter({1: 150, 0: 150})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Models\n",
        "\n",
        "Η προεπεξεργασία των κειμένων προηγείται της εισόδου τους στα γλωσσικά μοντέλα.\n",
        "\n",
        "Η διαδικασία αυτή επιτελείται μέσω των **Tokenizers**, τα οποία μετατρέπουν τα tokens εισόδου σε κατάλληλα IDs του λεξιλογίου προεκπαίδευσης, κι έτσι μετατρέπουν το κείμενο σε μορφή που μπορεί να επεξεργαστεί κάποιο μοντέλο Transformer. Η βιβλιοθήκη Huggingface προσφέρει εύκολες και high-level υλοποιήσεις tokenization, τις οποίες συστήνουμε να ακολουθήσετε στη συνέχεια.\n",
        "\n",
        "Συγκεκριμένα, **αρχικοποιούμε τη διαδικασία του tokenization με χρήση του AutoTokenizer**. Επιλέγοντας τη μέθοδο **from_pretrained** λαμβάνουμε έναν tokenizer που αποκρίνεται στην αρχιτεκτονική του μοντέλου που επιθυμούμε να χρησιμοποιήσουμε, παρέχοντας συμβατό tokenization.\n",
        "\n",
        "Περισσότερες πληροφορίες για το AutoTokenization μπορείτε να βρείτε εδώ:\n",
        "https://huggingface.co/docs/transformers/model_doc/auto\n",
        "\n",
        "Αναφορικά με το μοντέλο BERT, μπορείτε να δείτε τη διαδικασία [του tokenization και της αρχικοποίησης του μοντέλου](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer):\n",
        "\n",
        "```\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "Στα πλαίσια της άσκησης καλείστε να επιτελέσετε την παραπάνω διαδικασία με *κάποιο άλλο μοντέλο της επιλογής σας από το Huggingface* που να υποστηρίζει τον AutoTokenizer. Το pre-trained μοντέλο που θα επιλέξετε θα πρέπει να διαθέτει υλοποίηση με sequence classification head (κατ αναλογία της μεθόδου BertForSequenceClassification).\n",
        "\n",
        "Στο επόμενο κελί, φορτώστε το επιλεχθέν μοντέλο με τον αντίστοιχο tokenizer.\n",
        "\n",
        "(Αγνοήστε πιθανά warnings της μορφής Some weights of the model checkpoint at xxx were not used when initializing...)"
      ],
      "metadata": {
        "id": "3N0xadZjXiIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here\n",
        "from transformers import AutoTokenizer, RobertaForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "_lnywJkqyL64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298,
          "referenced_widgets": [
            "9b9a8103fc28450eb3373b29bb7ecef5",
            "be30f309d37d4efea6919450b774f748",
            "77d6b35711204bd28a47180737a11cfe",
            "ed6602613b264236a26fb5c0015dfe8b",
            "975641fbae1e46ceb5f4030c78ef823f",
            "32e76a05d5c344cdb1bdbb22b0d9de1b",
            "ff4094f592fb4df49422c06f1a9d6262",
            "f206c64333a84b92bfab9e3c72e6df65",
            "2f84e106b5ae45c6b21571254e05dd14",
            "514a58e62a764239a4d303140f3e53c9",
            "8e2efe48cad24410b0755760633cc887",
            "00acb8aa5e304fb98ab72e4b7c4529f0",
            "e0496062c29d4499b5793f8472b4d232",
            "80d095f4c0bb4541bcda8edc00bf97ca",
            "40035e7018c54201b5f03cd3df2866c6",
            "ad2dd6252fa74b6888e44fe872509f6e",
            "6a2be787eb674212b594023e657fbb25",
            "493b5c90df244153a2191fac7235521f",
            "e4701fbe2a7b4d819461c57f54c7575a",
            "cf08b33d22694972b3d2a370180e10b5",
            "92c72a01c5a344ffa72ecaabab567f91",
            "7457e78b9cd54a6db90ac06433c75c8a",
            "8280e34d95794389945ae1945a472afe",
            "28ee8cd15e0d424cbd7ae5fb96239f1a",
            "e1a90303bbc046d5a76c0368e7ae8ea7",
            "bd20b0b270254ad4aecca1f4fd30566b",
            "a0eadb2f8f504745a3148d8f803f1dd0",
            "7af5149d984c46cb8246ffa1924905bf",
            "99996c12f8ce4d0a9edcd04c064da428",
            "0628128fe81d487d89f5aace25012f2a",
            "7377d1e51fb34a73a706ed78bc882016",
            "2a45ad8f47bc4b6fa96c437e585183b8",
            "e5f07f02b6e048b0800504f5253982d6",
            "85b5a8cd6fca4c0da1071f03725933cc",
            "9891289c855a40ed9400ee56d11fadf4",
            "94678acdecaf45c091f39c4b2565862e",
            "e4ced7804c80453890f5a34e7761f86b",
            "ac0a13709b8a4683ac33db3d6a98490d",
            "3a14cc3119cf4166b5555b4663b2e4fc",
            "3de6f28cca754ed597e0fd9a8e80e366",
            "f35390dfab034e70b3aa788bcd0cd25c",
            "837dedd2559b433ab1c045c589a10752",
            "ac305d23b95b4e83b16c3040997514c1",
            "92cc3182ffc44830a2349c8f60d54073",
            "dc1050e4500844d6bf7959e1f552b83c",
            "20e7787e1c77490cbe96191ff236ecbc",
            "8495a45404ae405e92df1e951bea95cd",
            "959b0c74a138495da4de93f7722673c1",
            "7c7acf49032e42c49c36c5bb3e4bf412",
            "731c7994987c432ba16a4a078bebe1ac",
            "5de3a906e9f2416d8d8972e396037c4b",
            "3ca1852ea20f41969aed1bc3b5683802",
            "6d0722def2974f4ead52209fd47044c6",
            "43131c9bf79f4e6f8988d61309f17dcd",
            "7de64bceab60474994e9f654c27cedd4",
            "6c22189aa878431e8e8b6afee40ef73a",
            "0a0bc8e269824cbfa989c7e1994a1bf5",
            "b40b0211c3e34cd99dbc3abb617d44f9",
            "a7e17009170941768df6f9175c5153db",
            "4ebdf16bdcd349009e9cb46dd76fdad3",
            "4a4afde11549499684fb4e5070737623",
            "7bfd287690944fd78978ef4654ee06c8",
            "282bd5e00636449f89c9ce83cc342a22",
            "877810a5fb474955843dc44679437a73",
            "717e2f7c6aba42ca86984fb0507fb86a",
            "42431b00a4b241caad1f9fdf8fce4ce8"
          ]
        },
        "collapsed": true,
        "outputId": "5e6b842d-a687-4a0d-bb51-81958ed46ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b9a8103fc28450eb3373b29bb7ecef5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00acb8aa5e304fb98ab72e4b7c4529f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8280e34d95794389945ae1945a472afe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85b5a8cd6fca4c0da1071f03725933cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc1050e4500844d6bf7959e1f552b83c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c22189aa878431e8e8b6afee40ef73a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Σας παρέχουμε τη συνάρτηση που πραγματοποιεί το tokenization καλώντας τον tokenizer που επιλέξατε. Εφαρμόστε το τόσο στο train, όσο και στο test set."
      ],
      "metadata": {
        "id": "amArSfaYdTQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# insert your code here\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "eval_dataset = eval_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "-1AkZ0rLPq2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "57e252bb170249efaa9f90b597e957a0",
            "18f233f31bbc4a05a1c8f5aad1a0cdec",
            "541f800084cf49c2831fabd351a14c0b",
            "810e47ff6d544061bf3602660f8cb27d",
            "2d9c813135004948af5b3c6d8bfc1c21",
            "14be81d1a3be4c688f6d83a5b32b3c58",
            "b441ede1dfab464288da1cbe70dc08b7",
            "fdbbc38759694e46a3fb483ad5f40a55",
            "1feb746a675b47298dd0db91a3cb9230",
            "295bd55dce2a48ea9e6b53f7f7174d44",
            "2f527d1a4dce49848595ddeb254a4f77",
            "406dd08146c14a71b487ab4010086f7b",
            "b5e6523a7680421f9db69549ac7f7eb2",
            "78c0d12f4b9e46918eb3c0c24064519a",
            "7d79723caea04a678277df15c54aaae7",
            "20338ea315b6406da97cf5e69f4c057e",
            "1523dadff87d4088b996b56c8474b969",
            "6d63b7b0482440b98503a893ef10b421",
            "6d4fde4d9aa64f478c4be95aa478cd06",
            "bb038830052f4309aded57d8f5f8255c",
            "3816ee06a3024b73a2e4520358586d91",
            "c298d06799304e728cc37b18257a3d70"
          ]
        },
        "outputId": "ba83863e-cef5-4932-cba7-a4f404ac1fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57e252bb170249efaa9f90b597e957a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "406dd08146c14a71b487ab4010086f7b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Τυπώνοντας το train ή το test set, θα δείτε δύο επιπλέον πεδία 'input_ids' και 'attention_mask'. Βεβαιωθείτε ότι υπάρχουν, άρα και το tokenization έχει επιτευχθεί."
      ],
      "metadata": {
        "id": "9G6xI_ycdkGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(eval_dataset)"
      ],
      "metadata": {
        "id": "IWFzP_7SQVOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d619d3a1-ff60-4c34-b965-fac7edb1b533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 300\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 300\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIFmCKWS1Zj6"
      },
      "source": [
        "## Χρήση του PyTorch Trainer για fine-tuning\n",
        "\n",
        "Η κλάση [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) έχει βελτιστοποιηθεί από τους δημιουργούς του Huggingface παρέχοντας πολλές διευκολύνσεις και λιγότερη 'χεράτη' δουλειά. Προτείνουμε να τη χρησιμοποιήσετε ως εναλλακτική του να γράψετε το δικό σας training loop.\n",
        "Καθώς η Trainer δεν τεστάρει αυτόματα την επίδοση του εκάστοτε μοντέλου κατά την εκπαίδευση, παρέχουμε κατάλληλη συνάρτηση προκειμένου να αποτιμάται το accuracy του μοντέλου σε κάθε εποχή."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MPHrmRL1Zj7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ab55393ed99145e3984a6497f91c74c4",
            "e59dce414c0246299d9247e0e5e3b9b6",
            "e01cd82d67cd40d493b1e087bb97caa7",
            "b56df59f4f694750bfa1eaff9c6eaa07",
            "ff6a7b87d4544531acb98276f387df9c",
            "b65b6cecf6b342afba47e010939a7c2d",
            "50d186f6e11e4159acbfc80db2e18952",
            "a220b70073e84c2a87d777b39c4ed5c7",
            "d79b47010eca4d5c852f0ba437275980",
            "d9ac3d222b594e1f88f08b976dcffab2",
            "1725a341d42647b2bc1ee2ca3b626d0b"
          ]
        },
        "outputId": "45763c04-e06e-4640-bc96-200b7dccb234"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab55393ed99145e3984a6497f91c74c4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31RdBzz01Zj7"
      },
      "source": [
        "Η κλάση [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) περιέχει όλες τις υπερπαραμέτρους με τις οποίες μπορείτε να πειραματιστείτε κατά τη διαδικασία fine-tuning.\n",
        "\n",
        "\n",
        "Καλείστε να πειραματιστείτε με διαφορετικές υπερπαραμέτρους όπως το learning rate, batch size κλπ, καθώς επίσης και να ορίσετε optimizer και scheduler για το fine-tuning. Προτείνουμε να εκτελέσετε fine-tuning για μικρό αριθμό εποχών (άλλωστε το μοντέλο είναι ήδη προεκπαιδευμένο).\n",
        "\n",
        "1. Θα μας δώσετε σε markdown ένα πινακάκι με διαφορετικές υπερπαραμέτρους που δοκιμάσατε και το accuracy που πετύχατε στην τελευταία εποχή.\n",
        "\n",
        "2. Βάσει των πειραματισμών, πώς επηρεάζουν διαφορετικές υπερπαράμετροι όπως το learning rate και το batch size το fine-tuning του μοντέλου που επιλέξατε;  Σχολιάστε και αναλύστε."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga0fADv91Zj7"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def train_evaluate_model(learning_rate, batch_size, weight_decay):\n",
        "  model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")  # default num labels = 2 (also model definition must be included as function gets called multiple times)\n",
        "\n",
        "  args = TrainingArguments(\n",
        "            output_dir=\"test_trainer\",\n",
        "            eval_strategy=\"epoch\",\n",
        "            #logging_strategy=\"epoch\",\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            num_train_epochs=3,\n",
        "            weight_decay=weight_decay,\n",
        "        )\n",
        "\n",
        "  # insert your code here\n",
        "  # optimizer\n",
        "  optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=args.learning_rate,\n",
        "    weight_decay=args.weight_decay,\n",
        "    eps=1e-8,\n",
        "  )\n",
        "\n",
        "  # scheduler\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer,\n",
        "      num_warmup_steps=0, # basically no warm up more suitable for fine tuning\n",
        "      num_training_steps=(300 // args.per_device_train_batch_size) * args.num_train_epochs,\n",
        "  )\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=eval_dataset,\n",
        "      compute_metrics=compute_metrics,\n",
        "      optimizers=(optimizer, scheduler),\n",
        "  )\n",
        "\n",
        "  trained_model=trainer.train()\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1I4coXA1Zj8"
      },
      "source": [
        "Στη συνέχεια, ρυθμίστε (fine-tune) το μοντέλο σας καλώντας το [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvY7bzp01Zj8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "19d0bb93-cf7c-4b5e-ca38-5573800c71ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 02:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.281164</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.184761</td>\n",
              "      <td>0.946667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.240232</td>\n",
              "      <td>0.946667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_evaluate_model(learning_rate=5e-5, batch_size=16, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=1e-4, batch_size=16, weight_decay=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "JL9Sd24g-kMT",
        "outputId": "005db8a1-cfce-4bf7-e144-b6e8dbc34493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 01:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.327671</td>\n",
              "      <td>0.873333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.405010</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.256862</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=5e-5, batch_size=32, weight_decay=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "OqLeuU4O-kP6",
        "outputId": "822c8ac3-47d1-4631-dc0d-5f333ccf460c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 01:52, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.579584</td>\n",
              "      <td>0.723333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.203969</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.188078</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=1e-4, batch_size=16, weight_decay=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "31phYDGt_StB",
        "outputId": "e7a32ede-27ae-48b6-e5dd-2f88738b8924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 01:51, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.376934</td>\n",
              "      <td>0.893333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.361385</td>\n",
              "      <td>0.853333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.313057</td>\n",
              "      <td>0.930000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=2e-5, batch_size=8, weight_decay=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "lb0mbSXm_2-t",
        "outputId": "087e8e02-abac-45d9-9559-2a6ef78e42d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 02:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.221471</td>\n",
              "      <td>0.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.327875</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.242271</td>\n",
              "      <td>0.943333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=1e-4, batch_size=32, weight_decay=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "dkkntYYPEoaO",
        "outputId": "b5c1729b-a42c-43fb-d32f-3a6935060b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 02:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.200034</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.280777</td>\n",
              "      <td>0.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.273446</td>\n",
              "      <td>0.943333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=1e-4, batch_size=32, weight_decay=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "d92oNGkEF1RA",
        "outputId": "fe3a0671-07a0-4877-cb41-651c0b775753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 02:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.687044</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.275290</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.204123</td>\n",
              "      <td>0.943333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=5e-5, batch_size=16, weight_decay=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "emk3Yj7vGhrd",
        "outputId": "a99f3f0d-78b9-46a3-962f-c5e2a2a73d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 01:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.311758</td>\n",
              "      <td>0.926667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.323070</td>\n",
              "      <td>0.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.248170</td>\n",
              "      <td>0.940000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=1e-5, batch_size=8, weight_decay=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "t3W_H38UGiFQ",
        "outputId": "66579be9-7393-439f-8754-b0513243b872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 01:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.675654</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.315067</td>\n",
              "      <td>0.936667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.197105</td>\n",
              "      <td>0.943333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(learning_rate=1e-5, batch_size=8, weight_decay=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "HlTOD4PRGiIl",
        "outputId": "c9ca3448-4717-48b0-b6b2-d91b3b5f7ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 02:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.675654</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.315067</td>\n",
              "      <td>0.936667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.197105</td>\n",
              "      <td>0.943333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hyperparameter tuning\n",
        "\n",
        "| Learning Rate | Batch Size | Weight Decay | Accuracy |\n",
        "|---------------|------------|--------------|----------|\n",
        "| 5e-5          | 16         | 0.01         | 0.94667     |\n",
        "| 1e-4          | 16         | 0.01        | 0.94000     |\n",
        "| 5e-5          | 32          | 0.01       | 0.94000     |\n",
        "| 1e-4          | 16         | 0.1        | 0.93000     |\n",
        "| 2e-5          | 8         | 0.0       | 0.94333     |\n",
        "| 1e-4          | 32         | 0.1       | 0.94333     |\n",
        "| 1e-4          | 32         | 0.01       | 0.94333     |\n",
        "| 5e-5          | 16         | 0.001       | 0.94000     |\n",
        "| 1e-5          | 8         | 0.001       | 0.94333     |\n",
        "| 1e-5          | 8         | 0.0       | 0.94333     |"
      ],
      "metadata": {
        "id": "uFvsU7LBMzOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Ανάλυση Αποτελεσμάτων\n",
        "\n",
        "Στη περίπτωση μας όπου έχουμε είδη ένα δυνατό pre trained model και μικρό dataset (300 samples), η χρήση μεγάλου **learning rate** (>1e-4) δε συνιστάται σε fine tuning διότι μπορεί το μοντέλο να \"ξεχάσει\" αυτά που έμαθε (εφόσον μεγάλα weight updates μπορούν να αλλοιώσουν τα βάρη που είχε είδη το roberta). Οπότε μείναμε στο range [1e-5 , 1e-4] που είναι ιδανικό εφόσον το μοντέλο μαθαίνει (αυξάνεται το accuracy).\n",
        "\n",
        "Λόγου του μικρού dataset size μας περιοριζόμαστε σε **batch sizes** μέχρι το 32 ωστε να αποφύγουμε κακά accuracies. Μικρά batch sizes (<=8) προσφέρουν noise στο μοντέλο μας και συμπεριφέρονται ως ένα reguralization method οδηγώντας σε καλή γενίκευση του μοντέλου μας χωρίς να χρειαστεί να χρησημοποιήσουμε weight decay και επίσης είναι memory efficient. Απο την άλλη μεγαλύτερα batch sizes είναι πιο αποδοτικά (πιο γρήγορη εκπαίδευση) με χρήση gpu. Γενικά πάντως όλα τα batchsizes [8,32] που δοκιμάσαμε πετυχαίνουν παρόμοιο accuracy στο τελευταίο epoch.\n",
        "\n",
        "Η χρήση του **weight decay** ως reguralization method είναι πολύ σημαντική ώστε να αποφύγουμε το overfitting και το μοντέλο μας να πετύχει καλύτερη γενίκευση. Γενικά η standard τιμή που πέτυχε το καλύτερο αποτέλεσμα είναι το 0.01 ενω το 0.1 θεωρείται πιο aggressive και θα ήταν περισσότερο χρήσημο μόνο όταν παρατηρούσαμε overfitting σε μεγαλύτερο βαθμό.\n",
        "\n",
        "Συμπερασματικά, όπως βλέπουμε και απο το προηγούμενο πίνακα , οι διαφορές στο accuracy δεν είναι μεγαλές και αυτό οφείλετα ότι περιοριστίκαμε σε ranges για όλες τις προηγούμενες υπερπαραμέτρους που είναι κατάλληλα για fine tuning σε 3 εποχές. Τα μεγάλα accuracies που πετύχαμε επιβαιβαιώνουν τη χρησημότητα του Transfer learning, όπου πολύ αποδοτικά μπορούμε να έχουμε ένα μοντέλο που πετυχαίνει καλά αποτελέσματα στο dataset μας.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_SWX3b3YNA5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Μέρος Β: Χρήση fine-tuned μοντέλων σε νέα tasks\n",
        "\n",
        "Στο κομμάτι αυτό της εργασίας δε χρειάζεται να πραγματοποιήσετε εκπαίδευση σε γλωσσικά μοντέλα. Αντιθέτως, θα εκμεταλλευτούμε τις δυνατότητες του transfer learning για να αντιμετωπίσουμε πιο πολύπλοκα γλωσσικά task, ανάγοντάς τα σε κλασικά task όπως είναι το text classification, natural language inference, question answering και άλλα.\n",
        "\n",
        "Για παράδειγμα, fine-tuned μοντέλα για [text classification](https://huggingface.co/tasks/text-classification) εξυπηρετούν tasks όπως:\n",
        "\n",
        "- Είναι δύο προτάσεις η μία παράφραση της άλλης? [Paraphrase/No Paraphrase]\n",
        "- Συνεπάγεται η πρόταση Χ την πρόταση Υ? [Entail/Neutral/Contradict]\n",
        "- Είναι η δοθείσα πρόταση γραμματικά ορθή? [Acceptable/Unacceptable]"
      ],
      "metadata": {
        "id": "0eR7gCPovmFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B1. Piqa dataset\n",
        "\n",
        "Το [Piqa dataset](https://huggingface.co/datasets/piqa) περιλαμβάνει προτάσεις οι οποίες ελέγχουν το βαθμό στον οποίο τα language models έχουν κοινή λογική (commonsense). Συγκεκριμένα, αποτελείται από προτάσεις και πιθανά endings, τα οποία απαιτούν commonsense γνώση για να συμπληρωθούν.\n",
        "\n",
        "Για παράδειγμα, έχοντας την πρόταση \"When boiling butter, when it's ready, you can\" υπάρχουν δύο υποψήφια endings:\n",
        "- \"Pour it onto a plate\"\n",
        "- \"Pour it into a jar\"\n",
        "\n",
        "Ένας άνθρωπος μπορεί να συμπεράνει ότι η δεύτερη πρόταση αποτελεί ένα πιο κατάλληλο ending, αφού το λιωμένο βούτυρο είναι υγρό, άρα το βάζο είναι ένα καταλληλότερο δοχείο σε σχέση με το πιάτο.\n",
        "\n",
        "Για λόγους επιτάχυνσης επιλέξτε ένα τυχαίο υποσύνολο 100 δειγμάτων από το Piqa."
      ],
      "metadata": {
        "id": "vy3VluE4i3e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # insert your code here (load dataset)\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('piqa')\n",
        "subset = dataset['train'].shuffle(seed=42).select(range(100))\n",
        "print(subset)"
      ],
      "metadata": {
        "id": "v4eyhC27i8bH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504,
          "referenced_widgets": [
            "755b10c55edc411a98cf4375d8b13ce3",
            "1d5bff217db046f0a7b400cbe3be5004",
            "54030ef7df3141418e9ff2632664dd00",
            "c4c341fee2e441b78844fa4cbdec6854",
            "3bd0ba96530a413b92f546b9ca9809dc",
            "3017d43cd0e745239825c9ec69d61707",
            "37f5c8ec198545aabd051a60bf9d6a48",
            "15a0b9b59a294001a2190c092e09bf7b",
            "9e65b5b689624939bc04116249258428",
            "10cc1264cf3641c6987e57bc0287f21d",
            "2d73a280ab2341e882ece3b02eb112a6",
            "e7ea8688358843f28085563975c126c6",
            "97af483a61f949f7ade09a18f8c6489c",
            "ef63006fe80d4e95930418d369644f6f",
            "4987578dc9de4e09b9be3c8a5750a34d",
            "8f6d41f89f7348019fdb26abfb7d0250",
            "3429cd9ab92c4630bb5c691ef2009a06",
            "4cb4cce2b67b450c96bd51536000afaa",
            "29819d43d5b44ddb9894d43dc07b4f19",
            "594c96428955425bb7b334fea16c13bc",
            "1a02d74c1eb04129b4c594d419c0974e",
            "10322fb8789b4903ac981df791c6fd23",
            "f9708e2438f0420ebc440f94728574d4",
            "6597a1d16da54d30a281498188db311d",
            "57ebc52613734f27bfa639c784b6c28a",
            "554ae759561c4e51a2532f326bb05b95",
            "84fea762d90d4c4aa0be09de9b1b728d",
            "0cfcaddec1114868ba3e3095c5374d63",
            "f9ae4e0f5ac7404bbc1ef6f8223eff95",
            "923fa64ffe5b4281b3e27c7c285e0db1",
            "9611259962764bbbb99f94c2d38d774f",
            "f1cf8d52132248d69bcd3b0a93a1d816",
            "be39e2bd62e74a2d9baa9d4caf01ffce",
            "b505141652ea47918b2cb68161a0b2bd",
            "da431668f11a4240a8303df2ad47c7b8",
            "18a3de5c1f4f4bd4a0ee18bfbce30ae8",
            "8bbe6ee42d9f464f9420a07908daba03",
            "36d9d4da1c194315818c8c76d3891c3a",
            "e51683b4f3b1498d80a9715dbc631311",
            "e2aa9639ff08499fb69c0e7a7234a542",
            "0db69a89199245b0b9555e8089945e23",
            "67d898e05f474f6688e47361cb4438e5",
            "f499a1e152624c0588351f8816d684ff",
            "af588cb3aaad42ff91575943fc1d231d",
            "3abba55f599f431fba9066d2f4e3c45c",
            "8380f07e834c4e88b661dc5e594f0ac5",
            "faa3a8d1ba5449818e5bc8d2a75eb072",
            "0fd790740a384a8fb13b5a8734769967",
            "c143f9f51cee4dd79dd2554e07ce537a",
            "e6a681c3997541808de0585410784e5a",
            "f5d3ab0743004a43894d6489a4ad14f2",
            "9065dc8a9d0c48bb8ea74f0f874a1a1b",
            "f8734750a7b546edb2e05da7abdee3c5",
            "944a7437f9f84833a1f3120b3472a35e",
            "00b054716c7c4ad6807fd7225ebf87af",
            "6fad8095c66a4a8788c1da5d51cc1e23",
            "9095cb7b8cd9487b8815e5e461d00749",
            "d71e067ee1aa43d6ac3cfd17c05463e5",
            "206a9837b66f4803ba7d8d63ddb221fc",
            "2b9cee8214224de0903f6372fae280e6",
            "b17f7f7d2f7e4248a0a9c05040e35d9e",
            "04daa3c74720464ab4206e1b44e08f74",
            "11b4e1a3fed44b63b533883bf69291ed",
            "b60550417b3e4437afebb69f088d5f12",
            "7e496216cdba4f1e8a707a9d6f78aa9b",
            "e16ebdb6303e4bfcb641c2dee8a3e559",
            "b56bbf4cbd154881bc4e8e91704a93dc",
            "18e0f3d1cd6c4f7884ec98bf9eedf177",
            "1745fc8b19364fe1b239145d8aa5f9a8",
            "350b0d6d482d4507bbd5ea1cb2500d78",
            "435a77bdb23f48a6840d6b9ce77c3daa",
            "ce4307eb3a044b11bc52fbef79f36534",
            "219073e59d874817a4b265761ac93d7a",
            "e6569216646c490ea3e96beb844bfa2e",
            "1825f867e69946de9e78770719bd39c0",
            "d3d2f2b003564f53bcf3a0f4c669dbfe",
            "fb26a73b07ad447dbfd5d2a785b14f28"
          ]
        },
        "outputId": "95e8eb97-fdba-4c0d-ddb3-5811611928b8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "755b10c55edc411a98cf4375d8b13ce3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "piqa.py:   0%|          | 0.00/5.36k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7ea8688358843f28085563975c126c6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9708e2438f0420ebc440f94728574d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/815k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b505141652ea47918b2cb68161a0b2bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/16113 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3abba55f599f431fba9066d2f4e3c45c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3084 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fad8095c66a4a8788c1da5d51cc1e23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1838 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b56bbf4cbd154881bc4e8e91704a93dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['goal', 'sol1', 'sol2', 'label'],\n",
            "    num_rows: 100\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 rows of subset\n",
        "features = ['goal', 'sol1', 'sol2', 'label']\n",
        "for i in range(5):\n",
        "    for key in features:\n",
        "        print(f\"{key}: {subset[key][i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxW5PUvpM-lm",
        "outputId": "119e21b2-3d87-4249-ffc0-03824328b4d3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "goal: Do cardio exercise without running.\n",
            "sol1: Use a jump rope for 15 minutes.\n",
            "sol2: Run around a chair for 15 minutes.\n",
            "label: 0\n",
            "goal: To add a promo code to your Uber order\n",
            "sol1: Open the Uber app.  Tap the History button.  Tap Payment.  Tap Add Promo/Gift Code.  Type in your PROMO CODE.  Tap ADD.\n",
            "sol2: Open the Uber app.  Tap the menu button.  Tap Payment.  Tap Add Promo/Gift Code.  Type in your PROMO CODE.  Tap ADD.\n",
            "label: 1\n",
            "goal: wet towel\n",
            "sol1: hold  marker stains if washable marker gets on it\n",
            "sol2: hold  water if washable marker gets on it\n",
            "label: 1\n",
            "goal: Bracing the base pf your platform with 2 x 4.\n",
            "sol1: To take any wobble out of or base we will add two braces. First we will cut a 45-degree angle out of the top ends on each 2 x 4. This is so that you can attach the 2 x 4 to the inside of the platform. We will form a V with your 2 x 4 so that they overlap at a straight part of tree but also cleanly abut onto the inside of the platform. Attach the top of the bracing to the platform from the bottom and on the inside. Make sure both are completely flush before you drive nails into them.Drive an 8\" lag screw through the overlapping 2 x 4's at a sturdy point on the tree. Use a washer with the 2 x 4's and the lag screw for best results.\n",
            "sol2: To take any wobble out of or base we will add two braces. First we will cut a 45-degree angle out of the top ends on each 2 x 4. This is so that you can attach the 2 x 4 to the inside of the platform. We will form a V with your 2 x 4 so that they overlap at a straight part of tree but also cleanly abut onto the inside of the platform. Attach the top of the bracing to the platform from the bottom and on the inside. Make sure both are completely flush before you drive nails into them.Drive an 8\" lag screw through the overlapping 2 x 4's at a sturdy point on the tree. Use a washer between the 2 x 4's and the lag screw for best results.\n",
            "label: 1\n",
            "goal: To make a bar cart out of IKEA furnitire\n",
            "sol1: Purchase a Vittsjo laptop desk from IKEA and assemble it according to the instructions, then turn the desk onto its side. Screw in industrial casters on the bottom of the feet so that the desk will roll when it is stood upright.\n",
            "sol2: Purchase a Vittsjo laptop desk from IKEA and assemble it according to the instructions, then turn the desk onto its side. Screw in industrial casters on the top of  the desk so that the desk  will roll when it is stood upright.\n",
            "label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2UVjtPCOerb",
        "outputId": "98fc023b-7712-4a15-b59a-aa7145ba95c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'goal': ['Do cardio exercise without running.',\n",
              "  'To add a promo code to your Uber order'],\n",
              " 'sol1': ['Use a jump rope for 15 minutes.',\n",
              "  'Open the Uber app.  Tap the History button.  Tap Payment.  Tap Add Promo/Gift Code.  Type in your PROMO CODE.  Tap ADD.'],\n",
              " 'sol2': ['Run around a chair for 15 minutes.',\n",
              "  'Open the Uber app.  Tap the menu button.  Tap Payment.  Tap Add Promo/Gift Code.  Type in your PROMO CODE.  Tap ADD.'],\n",
              " 'label': [0, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μπορούμε να θεωρήσουμε το παραπάνω σενάριο σαν ένα πρόβλημα πολλαπλής επιλογής, όπου υπάρχουν δύο πιθανές εναλλακτικές για το ending της πρότασης. Συνεπώς, αξιοποιώντας σχετικά μοντέλα μπορούμε να επιλύσουμε την επιλογή του ending δοθείσας της πρότασης.\n",
        "\n",
        "Καλείστε λοιπόν να καταγράψετε το accuracy πρόβλεψης endings για κάθε πρόταση με χρήση γλωσσικών μοντέλων. Για λόγους σύγκρισης χρησιμοποιήστε τουλάχιστον 5 κατάλληλα μοντέλα."
      ],
      "metadata": {
        "id": "X_r6bijyOY_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️⚠️ Η προσέγγιση της χρήσης multiple choice classification head χωρίς προηγούμενη εκπαίδευση (fine-tuning) – δηλαδή, χρησιμοποιώντας το μοντέλο απευθείας σε inference mode, όπως φαίνεται να συμβουλεύει η εκφώνηση σε αυτή την περίπτωση – αναμενόμενα δεν αποδίδει καλά. Αυτό συμβαίνει διότι ουσιαστικά το head λειτουργεί με τυχαία βάρη (random weights).\n",
        "\n",
        "Μια πιθανή λύση θα ήταν η φόρτωση μοντέλων που έχουν ήδη υποστεί fine-tuning στο dataset PIQA. Ωστόσο, ο αριθμός τέτοιων μοντέλων είναι περιορισμένος. Επιπλέον, πολλά από αυτά αντιμετωπίζουν προβλήματα, όπως ελλιπή αρχεία στα ρεπο τους στο Hugging Face, γεγονός που καθιστά τη φόρτωσή τους μη τετριμμένη (AutoModel και AutoTokenizer δε λειτουργούν)."
      ],
      "metadata": {
        "id": "gqMMd4UwXGFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👁️👁️Για αυτό έχοντας υπόψην τα προηγούμενα θα πρέπει να ανάγουμε το πρόβλημα Piqa σε ένα κατάλληλο nlp task. Το nlp task που επιλέχθηκε μετά απο δοκιμές αλλα και απο θεωρητική μελέτη είναι το **Natural Language Inference** (ΝLI). Ουσιαστικά η αναγωγή γίνεται ως εξής, θεωρούμε το goal ως το premise και τα 2 solutions ως τις υποθέσεις. H υπόθεση (solution) με το μεγαλύτερο entailment score είναι αυτή που θα επιλεχθεί."
      ],
      "metadata": {
        "id": "KBGBKmL2YC2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (models)\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define NLI models to evaluate (these are specifically trained for NLI)\n",
        "MODELS = [\n",
        "    \"tasksource/deberta-small-long-nli\",\n",
        "    \"tasksource/deberta-base-long-nli\",\n",
        "    \"sileod/deberta-v3-base-tasksource-nli\",\n",
        "    \"tasksource/ModernBERT-base-nli\",\n",
        "    \"sileod/deberta-v3-large-tasksource-nli\"\n",
        "]"
      ],
      "metadata": {
        "id": "S8ZwmqzzI0_v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (function for ending prediction)\n",
        "def evaluate_model(model_name):\n",
        "    print(f\"\\nEvaluating: {model_name}\")\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name).eval() # no need since its in evaluation by default, also nli is basically classification for 3 classes\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for example in tqdm(subset, desc=\"Processing examples\"):\n",
        "        premise = example['goal']\n",
        "        hypotheses = [example['sol1'], example['sol2']]\n",
        "        label = example['label']  # 0 or 1\n",
        "\n",
        "        # Tokenize premise-hypothesis pairs\n",
        "        inputs = [tokenizer(premise, hyp, return_tensors='pt')\n",
        "                 for hyp in hypotheses]\n",
        "\n",
        "        # Get entailment scores (usually index 0 for \"entailment\" in NLI models)\n",
        "        with torch.no_grad():\n",
        "            scores = []\n",
        "            for input in inputs:\n",
        "                output = model(input['input_ids'].to(device),\n",
        "                             attention_mask=input['attention_mask'].to(device))\n",
        "                logits = output.logits # example tensor([[-2.7232,  1.9883,  0.2172]]), which are scores for entailment (the one we care about), contradiction and neutral, higher score means more confidence\n",
        "                entail_score = logits[0][0].item()  # index may vary by model\n",
        "                scores.append(entail_score)\n",
        "\n",
        "        # Predict the solution with higher entailment score\n",
        "        predicted = 0 if scores[0] > scores[1] else 1\n",
        "        if predicted == label:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print()\n",
        "    print(f\"Accuracy: {accuracy:.2f} ({correct}/{total})\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "wxBR3-ZHI1VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate all models\n",
        "results = {}\n",
        "for model in MODELS:\n",
        "    results[model] = evaluate_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBqSnw-3I1rD",
        "outputId": "579d17b5-8803-4773-d3e7-4da48f4c37ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating: tasksource/deberta-small-long-nli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing examples: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.67 (67/100)\n",
            "\n",
            "Evaluating: tasksource/deberta-base-long-nli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing examples: 100%|██████████| 100/100 [01:29<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.72 (72/100)\n",
            "\n",
            "Evaluating: sileod/deberta-v3-base-tasksource-nli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing examples: 100%|██████████| 100/100 [01:30<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.83 (83/100)\n",
            "\n",
            "Evaluating: tasksource/ModernBERT-base-nli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing examples: 100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.48 (48/100)\n",
            "\n",
            "Evaluating: sileod/deberta-v3-large-tasksource-nli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing examples: 100%|██████████| 100/100 [04:57<00:00,  2.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.84 (84/100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal Results:\")\n",
        "for model, accuracy in results.items():\n",
        "    print(f\"{model}: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHnjl3tbLNn4",
        "outputId": "8bc07620-b034-4f60-bb67-38b63b0b1cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Results:\n",
            "tasksource/deberta-small-long-nli: 0.67\n",
            "tasksource/deberta-base-long-nli: 0.72\n",
            "sileod/deberta-v3-base-tasksource-nli: 0.83\n",
            "tasksource/ModernBERT-base-nli: 0.48\n",
            "sileod/deberta-v3-large-tasksource-nli: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το **καλύτερο accuracy** που πετύχαμε είναι **84%** που είναι αρκετά ικανοποιητικό."
      ],
      "metadata": {
        "id": "lgJpl_tdFKR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B2. Truthful QA"
      ],
      "metadata": {
        "id": "Tz8-kVRS1w2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence Transformers\n",
        "\n",
        "Οι **sentence transformers** χρησιμοποιούνται για να δημιουργήσουν **embeddings προτάσεων**, δηλαδή διανυσματικές αναπαραστάσεις των προτάσεων αυτών σε ένα διανυσματικό χώρο. Χάρη στον τρόπο που έχουν προεκπαιδευτεί, έχουν την ικανότητα να τοποθετούν νοηματικά όμοιες προτάσεις κοντά τη μία στην άλλη, ενώ απομακρύνουν νοηματικά μακρινές προτάσεις. Έτσι, χάρη στις αναπαραστάσεις που λαμβάνουμε από τα sentence embeddings μπορούμε να αξιολογήσουμε σε τι βαθμό δύο προτάσεις είναι κοντά ή μακριά νοηματικά.\n",
        "\n",
        "Η σύγκριση των διανυσματικών αναπαραστάσεων μπορεί να γίνει κλασικά μέσω μεθόδων όπως το consine similarity, με μεγαλύτερες τιμές μεταξύ διανυσμάτων να σηματοδοτούν πιο όμοια διανύσματα, άρα και πιο όμοιες προτάσεις. Δίνουμε για το λόγο αυτό μια συνάρτηση υπολογισμού του cosine similarity."
      ],
      "metadata": {
        "id": "d59haHDaA3X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def get_cosine_similarity(feature_vec_1, feature_vec_2):\n",
        "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
      ],
      "metadata": {
        "id": "rdaiwnFx_ipu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Για παράδειγμα, εκτελέστε το ακόλουθο κελί, το οποίο δίνει μια τιμή ομοιότητας στο διάστημα [0, 1] για δύο προτάσεις (\"This is an example sentence\", \"Each sentence is converted\"). Μπορείτε ακόμα να δοκιμάσετε να εκτελέσετε το ακόλουθο κελί για διαφορετικές προτάσεις της επιλογής σας, που μπορεί να είναι όμοιες ή πολύ διαφορετικές μεταξύ τους, και να παρατηρήσετε τις αλλαγές τιμών του cosine similarity."
      ],
      "metadata": {
        "id": "kKMb7XFcB0Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "get_cosine_similarity(embeddings[0], embeddings[1])"
      ],
      "metadata": {
        "id": "UGhq0UGF-bW0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "3165057e957d43348f402b9132e9555d",
            "92956b68acce4238bdbc38042e4e6e34",
            "541ac0e8f09149949c990f400b1afe32",
            "5238f03d61c04577a1e4c73b96d8fc7f",
            "ae574fa7d0274aa7b6be8fbf37c156ff",
            "61aae04cb39d4133b5de9b20622eb02c",
            "6f6b74c7246a41e0848107b6d71f8fd3",
            "c09f0cd8886c4e8cb6f68c4a5a340cfe",
            "48441daf2abd4b40b332b8e534bd85d3",
            "224614a90817402cbf3080e315e536e3",
            "19b8332ef2434e71b785e2d8eba162fa",
            "a17334a4cb254f7791e25dff3438eabc",
            "948bb6ef450f4b739ac7c5f5717dbfc5",
            "9ae4a22645354c09a07695fbc7cd8721",
            "cf426bd9ac634388aa4809ae055a8929",
            "98d0ad17703449b7ba4b1e97adc697e1",
            "66582b550f7243a6bc5ec24f833cf97c",
            "cc6446fffdba4145b481e81ec553daf6",
            "a4526aba91294dd09115396291408a4e",
            "a7a1668a11da4179bd9015963542a68c",
            "331600fcdda342299a31552bd78f9c65",
            "cfa5e282ee7146bea3be971c6f4a7848",
            "5e33d8a214124ad487f1be9c5724f439",
            "cac63dbd19614b269152920ea0c4af2e",
            "8b84b4b8e3a34ff1a169274452c31d89",
            "4b050234044f4c4f9125ebd82cac6dec",
            "acba6e0e65314c208e7f7a74bed2fcf7",
            "9cac1c12a8214e9d854fe7c59d220288",
            "49b84592998c4109a062356797b215d1",
            "76406724956c43e186d74743394be43e",
            "2a9ba73ff52d40878d82918a4769a7fd",
            "cacff391362e4006a3f513a1c6603bf8",
            "76acd10a668e4505956e322159ea206c",
            "e8c88270eb1841d9b42705e49e141c17",
            "41f2d7638b244d47a4a473bff7e2f415",
            "766c5adad0e047ef8bd2ce409ac36ea9",
            "f8f4c646931f49808d11e133df9eac7b",
            "f1a99f241fee43069b3589cf4b1c0823",
            "69c7728871f14887b310d6692892d909",
            "3f3a6f5d3b8d4727bdb61aed16b5ef1e",
            "e019f0a75e514293b797854df8930fd7",
            "6dde7032933c4961ace8e1b381a01b05",
            "609f38c994414c809bae19a8c5c68070",
            "eef283f222334aba97052e7ce404f779",
            "3c6131ca1f314a6a971299cf917f504f",
            "d3b902eba46e4e53950226baa0f6aea1",
            "1662b2ef2ffc45978fcd48e061db80eb",
            "65deb44c8a4d4420a9104f71b17ccfb1",
            "df5c3bbb0e5b47d98b6ff1af74ecab28",
            "47e80ade3ac4402ea474869e79489807",
            "b7b1762eb1b4482a9b0f2256d403605e",
            "1b45fbcb1d0040aea13d9ba566c422a7",
            "a14da39ec715441aa6c989c0ce82596e",
            "4b6a8561590a43048cece3cac4b409c8",
            "891b23a72d2146cc8ffbae08aaddf694",
            "8f09222da79e4c14a527349b3c7867bb",
            "f07c6215892e491cbb0f3bd83c54762f",
            "f50f1729326947b5a3200684c6206c7f",
            "72a69905885948c9a727ec6ea007dd94",
            "249e4a9cb405489dacdc3df6c0655f9d",
            "67b6785210bc449fba95d049620ba7a1",
            "baae6997c4d34c30b2daad6fa51df291",
            "befa6b0f9a5147f5994f2e766da567e7",
            "8c958d86341440ec91ff76aa07c4272d",
            "767a6bc2be754163a967984967243aa5",
            "d408a60442f94769ae77cd122050df80",
            "0dc82e50cfaa41beabbd6d65f0bbef59",
            "5135ef379acc4da79dd8aeb182fd3b72",
            "f279101d28bf4249aee6b243dde33ca2",
            "29f8888d3ae54d008f4903f3c03d1a45",
            "1cf4aefbc7474a29995e3eb3b515298c",
            "a30996b8a7004728bec491dec46ec3ab",
            "7c2472a634ba4916ba77774e3928bb2f",
            "c517e9cf650c49aa978b2b419ede7fee",
            "7d16018a4c234744bd8687cd9d80bb04",
            "c49f73b6cd9d43c6b3e881947f26ba0b",
            "0f205a5ef1a24609af34da481609fe4c",
            "5c5ab0c61e6947628e774736ce76716b",
            "b7bdf8ab3b584bbd9945a0e26a47c55f",
            "6e673e3a7cd5439093726b4248678b16",
            "ffd3139132274a368d488a09329a8937",
            "cb00b08319e04907b27c9d2007ec4086",
            "5650cc596a47413aa469fca096b7fc30",
            "7918fda56e0a4f3ca3091f58bdd55a9c",
            "6abb50e67f6a449c8d6b00a69e93af21",
            "99cd2ecfb98f4eeab1b37b38b0f784d4",
            "2d39c12d695142d5ae91480ef79e609e",
            "4a08553ba8f9400d82aab8d76222b599",
            "761182c94c744537a369d909234f66fb",
            "98a4f0ea7e074c30bd3967372e8f6712",
            "4f62094968644fd28be27624a8138dac",
            "7c04f9b7adbf4087a85ebc89e02e9e93",
            "e064b369f2b946b9bae0385a16764ace",
            "45b326b73464463ea8356a9072b0c458",
            "fe35d6fd67b9435ab955fab41dcf5886",
            "c00e2d6314674e2fa0c9aafe6c639e93",
            "1182f090ca48425698f2e9c92c266e5f",
            "8002056132f84a01b0db775e9420b10f",
            "27b7970cecbb4cd9abed944391f44da7",
            "2a4eec008be9480eb1f590c9f799f1e5",
            "e2b1b00fbf744015ad6112acfcd19d23",
            "1d779997d8894f91839b4dba57c83410",
            "d22061ec905e48aeb708b841b58770e2",
            "ef0b1f18bb8f4690b5491e5cddc9f5e3",
            "6d27639d40ca46219a1e62328d2fda14",
            "cffa1835c8d1462db8bd064690f62e4c",
            "8908b56112554491b5741759ff88728b",
            "9c709754c2ef4a1d822641ea94b100ce",
            "495b60267c91459899ab703b32b6967b",
            "f9ce79a238434cf586bb3d401eb8db74",
            "cda131db1aef4018bc153fbb7ecaf076",
            "ebefd49467f047058877995319e54f5c",
            "110da25a5d8f46309b92510cab70a602",
            "61d199a34d9e4a5cb1b5e51426526df4",
            "1c306eaea85544a1be8737daf282f4e1",
            "917130c226934f5ca53b0c007eb06a91",
            "432180da9bd4451e95e36ceea29a010f",
            "85e5a1d9a88c4c44af7286561cae77f3",
            "a16ea4c45cbd4bcab7a789a3749070b5",
            "219ffc854c9e469fa37506de1fffbc9d",
            "f8cd4db4ada64aaca6cd81dae98e5ae9"
          ]
        },
        "collapsed": true,
        "outputId": "d2cbd2f4-ae6f-4188-872d-976828837b7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3165057e957d43348f402b9132e9555d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a17334a4cb254f7791e25dff3438eabc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e33d8a214124ad487f1be9c5724f439"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8c88270eb1841d9b42705e49e141c17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c6131ca1f314a6a971299cf917f504f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f09222da79e4c14a527349b3c7867bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dc82e50cfaa41beabbd6d65f0bbef59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c5ab0c61e6947628e774736ce76716b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "761182c94c744537a369d909234f66fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a4eec008be9480eb1f590c9f799f1e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cda131db1aef4018bc153fbb7ecaf076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.40488452)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Για τη συνέχεια της άσκησης, καλείστε να επιλέξετε τουλάχιστον 6 διαφορετικά [μοντέλα για semantic similarity](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads) από τους sentence transformers"
      ],
      "metadata": {
        "id": "Rzaa750mCZp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Μπορούν τα question answering μοντέλα να διαχωρίσουν αληθείς και ψευδείς προτάσεις?\n",
        "\n",
        "Αυτό το ερώτημα θα το απαντήσουμε στο παρόν κομμάτι της άσκησης. Για το λόγο αυτό, φορτώνουμε το dataset [Truthful QA generation](https://huggingface.co/datasets/truthful_qa/viewer/generation/validation), το οποίο περιέχει τις εξής επιλογές:\n",
        "\n",
        "- best answer\n",
        "- correct answer\n",
        "- incorrect answer\n",
        "\n",
        "Πολλές φορές το best answer και το correct answer είναι ίδια ή έστω πολύ κοντινά νοηματικά. Σε αυτό το σημείο είναι που θα αξιοποιήσουμε το semantic similarity για να αξιολογήσουμε την ομοιότητα αυτή.\n",
        "\n",
        "Φιλτράρουμε το dataset ώστε να περιέχονται 100 δείγματα συνολικά για λόγους επιτάχυνσης, εκ των οποίων καθένα θα πρέπει να περιέχει τουλάχιστον 2 correct answer. Θεωρούμε έτσι 4 υποψήφιες επιλογές:\n",
        "\n",
        "1η επιλογή: best answer  \n",
        "2η επιλογή: 1ο correct answer  \n",
        "3η επιλογή: 2ο correct answer  \n",
        "4η επιλογή: incorrect answer  \n",
        "\n",
        "Οι επιλογές αυτές μαζί με την ερώτηση δίνονται σε ένα μοντέλο πολλαπλής επιλογής σαν αυτά που χρησιμοποιήθηκαν στο ερώτημα Β1. Μπορείτε να θεωρήσετε τα ίδια μοντέλα και να τα επεκτείνετε σε 4 υποψήφιες απαντήσεις.  \n",
        "\n",
        "Το semantic similarity θα επηρεάσει το τι θεωρούμε βέλτιστα σωστή απάντηση, άρα και το accuracy. Συγκεκριμένα, θα λάβουμε διανυσματικές αναπαραστάσεις για το best answer και τα 2 correct answer που έχουν δοθεί ως υποψήφιες επιλογές μέσω κάποιου semantic similarity μοντέλου. Σε περίπτωση λοιπόν που το μοντέλο πολλαπλής επιλογής προβλέψει ένα εκ των correct answer, και η ομοιότητά τους σε σχέση με το best model ξεπερνάει ένα προεπιλεγμένο κατώφλι ομοιότητας, η απάντηση θεωρείται βέλτιστα σωστή. Θέτουμε λοιπόν κατώφλι ομοιότητας το 0.95.\n",
        "\n",
        "Για παράδειγμα, έστω ότι το μοντέλο πολλαπλής επιλογής μεταξύ των υποψηφίων [best, 1st correct, 2nd correct, incorrect] επιλέγει το δεύτερο στοιχείο, δηλαδή το 1st correct, και δεδομένου ότι το cosine similarity μεταξύ των embeddings του best και του 1st correct είναι > 0.95, τότε θεωρούμε ότι η απάντηση είναι βέλτιστα σωστή, και συνυπολογίζεται θετικά στο accuracy.\n",
        "\n",
        "Καλείστε λοιπόν να γράψετε μια συνάρτηση που να υπολογίζει το accuracy εύρεσης βέλτιστα σωστών απαντήσεων ανάμεσα στις υποψήφιες απαντήσεις, εξετάζοντας τουλάχιστον 6 semantic similarity μοντέλα καθώς επίσης και τα μοντέλα που επιλέξατε στο ερώτημα Β1.\n"
      ],
      "metadata": {
        "id": "8iGiDmwBCuKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👉🏽👉🏽  Το τρέξιμο κάθε μοντέλου απο το προηγούμενο ερώτημα 6 φορές για κάθε sentence transformer είναι μη αποδοτικό, ειδικά όταν πάρουμε υπόψην το μέγεθος τους. Έτσι για κάθε μοντέλο, θα χρησημοποιήσουμε 2 sentence transformers ώστε συνολικά να έχουμε δοκιμάσει τουλάχιστον 6 sentence transformes μοντέλα."
      ],
      "metadata": {
        "id": "qCl5m1e4cl2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (load dataset)\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('truthful_qa', 'generation')\n",
        "subset = dataset['validation'].filter(lambda x: len(x['correct_answers']) >= 2).shuffle(seed=42).select(range(100))\n",
        "print(subset)"
      ],
      "metadata": {
        "id": "B3aXIPmDIA7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "7186f9b5b0c94c6fa38061979f571241",
            "1cb4535fb23943d681c8fafa06a9c17d",
            "b203f4828d494fafb2c00164f8209c49",
            "6c0b0692036d477892a79c1bda7b1e70",
            "ee7a17958722416aa666cc0e4e37bd4c",
            "5ae56edb359f40da833d651b0eaea3a1",
            "bdd85768c8264004ab248a6026f3571b",
            "2a5512326bd24f758c2c1255ab41ecb1",
            "60e0941ea5ee47ab8c646b5e128ccbcf",
            "a3d1a7da7d524071baf7d72edee0665a",
            "2b52d98e54ae408e8d31c8ee6c710805",
            "c87b76f9121a4b65bc53e358dd64388e",
            "b76dca2f64b643589730c6d845bdc26c",
            "fd3a7db52c944091b7bdb069e36971e8",
            "8d6d048a0f3f481ea0372de6fcea145b",
            "9dab032cf9724c7d8d785df36c94cf0c",
            "bb165d80507e4104b10b2d7350b2a5f2",
            "4bc15eda88544c20a5b4ff7540805f45",
            "a98ba43025a94680b93a9467a1ffb3b7",
            "7cee03f357094bb382ad607ac2c9450e",
            "ac43247dcb54451cb8372fed55b9213f",
            "77dfb04998db4a1aa79582e757daa34b",
            "5375e98845a64b83ab29575e15a36a8c",
            "69b1791f1f8d4ab5bf8aa02f8b2388cc",
            "7f16ea0d6d584df582ed9f13db4cda64",
            "14b16c2070b24e7ab7e1124ae6ae0c4a",
            "ed35d6ad034c4c749c7bf2ce7cd7f88b",
            "8ebf61c4c9b44f17ac64922a795e1143",
            "50418028cadd455cb7fe0a39bf22224f",
            "3de16ac8478d426e9675806f63a86c14",
            "9d6411e332d747a082864c6b0868e854",
            "cbdebcc0daab4aef862c997600310968",
            "5206601ed8c1486c97acd79f20fcc2a5",
            "965462fc3ff04958a26324b095157396",
            "2db273b5d6064b2386e07f1e6d34549a",
            "d47a0db0d3d2406986ebd5a22eae407f",
            "a763a39ae22a41b7a8c17b7b1ba42d3b",
            "1c718ef3b7b2415da87e59aa0c1ecec9",
            "a5a2cdd9e7d149f99affd8aa29c4c8e6",
            "839bed86900f4054ba3a0a4282fb0276",
            "bd0f829c11454267b5046ca0c075104b",
            "675a60592579423fbd7ecc09336fb7ff",
            "04378ddd7b2342e0957bd424e44d534a",
            "3226d036d324486c8f25f323eb8ece5f"
          ]
        },
        "outputId": "f9ad4959-d142-4e35-ab53-921a7f2edbc6",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/9.59k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7186f9b5b0c94c6fa38061979f571241"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c87b76f9121a4b65bc53e358dd64388e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/817 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5375e98845a64b83ab29575e15a36a8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/817 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "965462fc3ff04958a26324b095157396"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['type', 'category', 'question', 'best_answer', 'correct_answers', 'incorrect_answers', 'source'],\n",
            "    num_rows: 100\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (load models for semantic similarity and QA)\n",
        "SEMANTIC_MODELS = [\n",
        "    'sentence-transformers/all-MiniLM-L6-v2',\n",
        "    'sentence-transformers/multi-qa-mpnet-base-dot-v1',\n",
        "    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
        "    'sentence-transformers/all-distilroberta-v1',\n",
        "    'sentence-transformers/stsb-roberta-large',\n",
        "    'sentence-transformers/gtr-t5-large'\n",
        "]\n",
        "\n",
        "# Load all semantic models once\n",
        "semantic_models = {name: SentenceTransformer(name) for name in SEMANTIC_MODELS}\n",
        "\n",
        "# split them into pairs\n",
        "model_names = list(semantic_models.keys())\n",
        "models = list(semantic_models.values())\n",
        "pair_list = []\n",
        "for i in range(len(model_names)-1):\n",
        "    pair_list.append(((model_names[i], models[i]), (model_names[i+1], models[i+1])))"
      ],
      "metadata": {
        "id": "IZSQmLMDIJ3A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6ddc2d294ebd43b79391dfcc3c785672",
            "a5bd1e7c8bb149d8963de2752c5f998c",
            "51582cf54b424dd2bd848a2562c18e8a",
            "65908720741d44b4b37ee10ece304ec8",
            "70620b88cbf24b2fa2257d7bf764b9e0",
            "0b2eaa6a73ab4e5288d38358a8d0a384",
            "bdac3983637b4a2eb06eaf7848c86eb5",
            "80fde00ebdb9478ea49c99590a40b45b",
            "1fa280bb5e5540e9bb66d713d9fbe584",
            "56bd51ea9d9249c195ee1d32a5e5dfd3",
            "8fc8d8b8f05041c5bbb076249a3c70b6",
            "5a74f8cc600e4ceda64082369847fd7e",
            "a6f3c119d8704df1a44a2ae8ca3bbc63",
            "404851af27be46b0a556683605de6497",
            "e662ef735bca4df196fc596d7e4db6a0",
            "a7a0d8169f624cbd9333c7bda24e9df4",
            "adefe7d0d8f542468c3d97d7f3350730",
            "f52f8407167c4f6babff7aff1943f2b8",
            "6f9638663dbf416bb2e6cfd3e34d9f5f",
            "ec3a2a98094b4bc79da96aed92a0cdad",
            "93fab13dba7d4b60bb2c50e54c3d3a75",
            "8e92b027b8374f498666e13370fe7973",
            "d2c60088bd8048129fe2ce73ec97f6d3",
            "5ae026c384b649b3bdff740523869ca8",
            "31338c5eae5f452bab05ba23258295b7",
            "f594d23eef9b421db5bbcb07b323244f",
            "8c9945f547a44e048ac1c74c8446b979",
            "1eace233379b48c794b8297b912d37c7",
            "d801c5e7b65b4a6f83d205ed97216dd9",
            "f68ab1e79a4644a29ae9986c79ce4955",
            "6c43805502a94034b089cd94d12b114b",
            "6052420ea4c046fba0b3e6b598966691",
            "64d88c4cfbd04929936643b41332b146",
            "499496d77bae4089a1b6df207332f5e0",
            "f8fa870795d1404e81d2424dd2df42db",
            "b0fdd0699a254ab6ac3b31c507e28b07",
            "c6f114b147bf4bed80520736f67f24e1",
            "2354db1fb1254eef8c27310b1a6339f8",
            "b79b8151074b428696842b894066afa2",
            "12aa4b5004a84af3bca1400dcde303ee",
            "2e239ec30bbb44eba1eb9ebcab8e8026",
            "8a35521a35c74aba982167d5076e1c4b",
            "94b6b5d1c325470d8ff9429f9169ea1c",
            "f917a31d867346ff8fc3d09cee349975",
            "3c4f6cbd552346f297e002f29b98d32f",
            "ac1ba48a90024989bd4dc1a68377221a",
            "89c61583df2f4d21a9b6323ae41c0f1c",
            "c5340aa5b58049ea8ae543480791195f",
            "dd1c6e4231e345398d8ca6bfebacf2fc",
            "a10f664740154f2daf672920d5eb6d94",
            "8d7332b65b1d41b5a21c48ebeb7bad83",
            "d88b94c014de442b987deb5ebf368dce",
            "6346679d11374f18b0691c96e052583a",
            "e8f0bd1248f6420294b10c17248d5150",
            "2bca55ea8bd7449b963d853abc6fb457",
            "68e1bc33627e4416b1a294d4e8b40144",
            "f248d7e82d2840379f7f114782f1118f",
            "96a08e8386804d3993be3a0cb41a7520",
            "49d7e383cb1b494480784e21a623f147",
            "f544968d72734f1580774724f17b2a41",
            "87d9f6e7a1a8478bae50fe002f9ca800",
            "7133105faa2d4b5fbd13749163fbf160",
            "af123fea6ee14585a1ae3012581692f1",
            "ff84d3e64c9e4efcbbc85b56be4b37fe",
            "c8e5a4d2389d4155b4e21550990d2eec",
            "7f5f403a49e445db829e5ce7686ca4bb",
            "062b635ab68d4218bb68dda661891df1",
            "a67b9c85b3704477a9de7752857547ab",
            "7b12367eca50428baa7e9c68eda82acc",
            "832c83fd44cc417d8b3b20d2fd3c9432",
            "c8a6227a44774c4ea1ba63b4eb5bb2e8",
            "9f90887fd80447cea2f7ddd513a68f58",
            "48c056a7112141b288c3c1eccafba375",
            "e002c0901ba043d3ba51fc4b9fdf97e6",
            "7c42556654a540748ad95f2a40ebbe53",
            "e0f47cabcf01454ba930311a70a5a3a0",
            "0ca892ddd7974271b12c38eb6d39e4dc",
            "ac595e74747149b29443c9114a2ba7fd",
            "3f71624fc5c64e6abf70c380ee406a68",
            "3fce4e14d7154c37858238a8062ed1dc",
            "21040e82763140a08839d8bbdbfd97e5",
            "f00eba35e43c48769a128b46773b9020",
            "0680d3fcbf8f4109b3f3a0be52564f64",
            "3f9047d46bc544cf916907d0dbf9dea0",
            "94136915b5eb4154a667e73c1145ff77",
            "39f760196b384b0b9430f08f6500ba34",
            "b6e450fa881643b2ad9c96ae1a73fdf3",
            "e26be0136dc44f73b331b8c1ceeed079",
            "7d6d571431de4581b61337d5c20bec83",
            "72434869c272439292be7d04d602d4dd",
            "04d6e1a5d3ae4332b474c7f50e790b27",
            "e8da55ce8cc34d1d93babb9f31810f6d",
            "c8e9ced89af64f758fb96e330d9ce8b1",
            "e556f385e714469c88b6ccb3d870dd14",
            "9a0bfc10c4b94b7f9708c0d3fb764316",
            "5398fd8cc2a6413bb3c1840805bd7a6d",
            "2f2358e6e85c481bb429d77bc669e7df",
            "86f0532079424e7384b5cb2152c764cb",
            "21dc087fd4bf4201a4580e8acbc8d948",
            "4633055494184e33afa26ca8aa859a90",
            "d1df17f44c8b4cb1846965a77b8a67ec",
            "959a08bec57240f68f6522cd4d1ec6ab",
            "764449ca67444fedad53d2e72536f3d0",
            "8dfecd57a73f46bf8215553bfb19e4dc",
            "e45262798a5444a2b6dcb622a874e7e2",
            "457bc46de5984c15a209423ee1490071",
            "d4e2829298734075b8557a8182161bb0",
            "8d8e533392a54336b1c80cab42c8ee74",
            "7f4ca95644de48a3b79a09ae6f7bf6d9",
            "26fec1b5c6b44e4188874465e573f628",
            "ce4fc5e157c2464aa2f4338850d963d1",
            "26b454113bb0486dbc266efa6896309f",
            "c1addaa6d77e4c9cb6bf683b1af92ea8",
            "3f609c0761814243a6a648a80e6f77a4",
            "27629572800a464795509e9c55a067fe",
            "437e29568e7b441baf36aada943514ba",
            "2f899f70207248d7abcc2c9bd6deb518",
            "d75ab199dbea4ebd8be12376311f3b70",
            "26eabf5b96c549209135a6112fb1c6b8",
            "4328cbb31be9472493ee37434101b9b2",
            "8aac91eaa5cd41328df392334510780d",
            "55fc7c6434b84f67be37116ae5d77f34",
            "83d00da73a654213b65e31c3ec5632fc",
            "d7e021b91e314d5b8202648b947078ad",
            "9481e6f3d1f741d0b509b1769a3f07bb",
            "97be28244826434d8a779e6ce699a182",
            "fd7606949df24119aab57276b4a1d497",
            "d3858a8cfa124f5a83553fc534608a99",
            "bc6ec1ae51d34137b4f9abda896a6093",
            "3b195ed44f3f4a1caffabf4f42207f3b",
            "85e4e100817e428c9b9a18439d572e82",
            "22ede93b64e24d5394989cad425bd7d5",
            "20668c2bec76429fa9f5530b6644b342",
            "6cda780fb13e456a92b9d2600980d310",
            "6a06a7ee8a4948e28c655077972d63cf",
            "0bdb471b4b814cd6a1368ea721e99aee",
            "00eef7db1c3046ed8e3290b66f3977fb",
            "d759a89748d04ec4892a722e6ff95cfc",
            "8ef4fcda190946aebbc4e07fa7307dd2",
            "5005a0b65f74459fa6422d5f5ca4fc72",
            "4d123c536bbf492793231309505ef4af",
            "563f124b76144313a0241850161ecd2f",
            "b311a48300a64c84a01cce52d7d46595",
            "26dffea670484e4dbd5e8d75d831a2c1",
            "557950cf0afd43a3aaed31d1ff7f41ff",
            "cd91eef430ff4a6c8e883eb04d04ce29",
            "f82bec0b1b8249338e605d3888077706",
            "a3451ed1ec03455ebe9042e1e69dae9d",
            "59f480be76904f6abde09ab6909c49bb",
            "822921d4190e4cabb852c6791ca217d5",
            "b64e31fa49f9434b8529ebc34d89e014",
            "cc6bc76c19724c5ebffbfa89d7d1690e",
            "bc34d4d88e1845388a23673107ea7ebb",
            "a13a4b5c279b4febb52d966292c9ff4c",
            "7310fbfd78ae4644b7ed644a647c3912",
            "932c26f4d1c241e0b9df69038b2dc7fd",
            "74cdfe1f1e704ca79491527bd294c457",
            "0ee2b14ab05d44b8a215a9b178abeff5",
            "79656b2b3009460d8be8db77c52a2c07",
            "8ce767f46e6c4e8b8700d8f7ee4fc4cb",
            "10c5a840a9364758a29cff9ecb02b059",
            "d677900ea06c455ba33367172357e84d",
            "a3c9ae5753744a779895395e7a433ce0",
            "4988812b091d48809391093cd0a03ab6",
            "afc0aee7b292439e88a92f16780fc3d3",
            "162310c3d86340348f39de7f23102ed5",
            "d472727383ec46689195bc9436042b02",
            "94c21c3d37ef4add964508ab80a74242",
            "c0a4af64b05340e8908d061f5ba38721",
            "28c536eed21b489ea55ecf1bb7774495",
            "57baa012240141dfa812186fd90f5b6c",
            "78bdff7192124dabaa38766d420353da",
            "4c0b6e64226743ea821c15adb06fce60",
            "ea0a447e45534275926069bff49306ad",
            "cde1d34f5b394f3fb7494c920da2dadf",
            "6bb67386fd544f8584365ae89fe7a901",
            "8688ed3a904b45cfaa326de4c190c598",
            "a45c27473931464da6683fa138243c05",
            "e29b2d5813f4476cac6398f1dd51e789",
            "8b226ea448d84d60817e1c0f4ea5dbc4",
            "8e467ec8448f4fdd961e60db76d4540f",
            "7b5273086f23441083588208ad434d38",
            "d766a9ef8fa940b089a1db3034ec5deb",
            "775baba9d1b141aaaa06f181c2c85176",
            "dbf2534c69de4330bf0f3cf20a2d1d39",
            "8f751101e7ca4bc9b3361fa04c429206",
            "a78d84bdcc0a438e85c2285cfdeb454f",
            "add55f6981544feda1a1bd9dec296285",
            "6672601706874158a4a4be72f6ba8eb3",
            "da4d21b5648d416395ebfc9aa766d567",
            "c0c7f337727c4097bb842039005dd955",
            "7dc0bdc98b7e441a87f6c0378decbd07",
            "4532c46f377544f399591a60e2080a99",
            "cbf0b729ce4e4848b0bcb3b21dd3c70d",
            "61e00179fccf4fc9a80d3c9d212ab2f5",
            "a1afbe52c05b4b799ec091f697936470",
            "fc221eca3f9c403ebaca01bc087417ac",
            "d9516901f929419491abaec0538c9a9a",
            "baa93b567dc1418781ce4478b3cc8867",
            "4e33265c976c43fc907566aa1e162694",
            "1d0b4242e0d7415ea7677cd2adcbdd3d",
            "633cffe4b4b940f48a9d250281571b72",
            "ed05a04cd76148139e2de1e04b5b111b",
            "fe0d1c4d59f9440ab4dd39ee0b2dcb0f",
            "e56cda2fd9e54f16ae667bc281388be8",
            "285283fcf31641669a2f12d4dc1759e6",
            "df26b7758d70482ab6e6ea24a813ace6",
            "505184afa16d4f4aab1f6833f0e4da7d",
            "9eca82ecf85c491bb41bc589d0c16839",
            "f38bb8f6c4c945e996486119edaba0b1",
            "934f71507c0e41d786f25bc0f6a43e86",
            "71a0586a2e4b460a974f0e21dcef231c",
            "91ed2f9329a54392ae88512031571e3b",
            "b3d3cca201574a73996674ef5643b913",
            "3e6a375a0f1c4554a14c116d9632d8dc",
            "31edebfaacbf4466a96eae1d7031e75c",
            "3a477c6fa5a341d4b998a8a369316567",
            "57600dc4a486486ea11ea3ce908cbbd0",
            "f55ff28d072047bdb9f8c1b534fa9b51",
            "f779079926084f579820539d09763669",
            "2a3eb2813d5d44eab23322f7ab822e23",
            "2cbe729e9df64619b486b01f71157054",
            "1aa28541f71a4ccd8380b017388aa6e9",
            "bf70fc2813f04e4985e1ba1a2ceee455",
            "1a4fd35d4ec0452f8c40428f8205c029",
            "b4294be79acd47e69e4f37fe2137fbea",
            "ddcd2b30453547a083ca9dfbf21f4cf4",
            "dac50619916b41a89d5ee570324b4ee2",
            "b29e2b821c1e4c1aa0bcc3f1117bd6d5",
            "eb706296ac1e40a4911c559a18228202",
            "56c26475100040da9a66817ba1b12dd6",
            "393aea5b944a467dbd28e2921e2d05d3",
            "71dc90a6d1764dddb0684b155cadbbd4",
            "f9e8162a9c5b436699e56a10788f0d80",
            "f2992591ac6e4053b496e8f9dc712886",
            "2f16bc4133fd40948910d1051d36bfec",
            "06933480885e4c80a3be5c47c1929961",
            "4c8de94eb1e4443d936eb63f4b5c6720",
            "4e105c5bbf094d72be38113b7bd01329",
            "b27ecdeb14ac4fd591730aebbe62fb31",
            "aa2bb1ed864b46f9a3ce130e3ca61841",
            "33a2121620084e3e9c78dd31aa6add5c",
            "5921526d48b841e28de008edab1cac14",
            "671464a4b0be4008a94b2b0e6e87cd7c",
            "9504f6eed3ed403f98526d6e062b2744",
            "e6c7080eb5af49b3836339f55d0d6a38",
            "33ef13f2457f4453875be8fdbf64e9e4",
            "0333de5209bd466384e354715d6ec86c",
            "a47300ea69af42a0950d1225ab3150e4",
            "332d8e1325364da1aad804220a7d4e88",
            "840a1bf6f797467997827b915de97a01",
            "26cb4ccadb8b4bb3ba12f0cdcb8309f9",
            "42b5f6d8c5cf4daaa1a6ea3eb4b6982b",
            "c9167b699ea84ddead1c640ebc6b272b",
            "4f27866f228741f1b9452ac8dfd216a2",
            "07b9d34081bc427084b3c63740aa54fe",
            "2d18de4cf36c4b6c9f0d33b5f3dac828",
            "91422da536264fd4ad758a5950d568e0",
            "553fcaa429d74f0f9cbef342ca9df95b",
            "dd73bb39ec294eb79e6cfbcb03c3b94a",
            "fb99b3a8c9044c99b46e7ca17225b052",
            "9d9cbf316b5342c5aa898d0f3daeb523",
            "4dfd18f55bff4defb9f2fe1d3ac7689f",
            "3d50271efcbb46119419ead2742ed9cd",
            "147b9375e0304a80b29d88c96b09e787",
            "615835f030ae40d19b92dc6085411c18",
            "32920df86c58467ea57a08cb46e5618b",
            "a159f77075e948f18734bd5dc9dadc03",
            "56cc1226aad04160bae5ac445ac77a0a",
            "483d7ccf84b947fbb7123b09a3376faf",
            "2a21c206870a43b7880f3f6add2ed747",
            "cb4d6fe385b54aae94078100e058a9da",
            "c36e5000680c4ebd9d5efe58612c630d",
            "43d32461d0524ea3849c04abbf36e299",
            "e8ff1c59713c4c52ad8af3fe79bf2ec0",
            "324a79c6fdf3465888875c87ba03ab34",
            "4f3d069a5b754c6d84d8d1d40a4e2d03",
            "3bdeafd6e575464994e6b9c9e604c8ee",
            "db388373a5f944f2a20646ebf6a1da4f",
            "2ac4d2ba8f2b4353b569f65c4d81c338",
            "d2d62cec141249e6afcb8eca87c66a81",
            "449c284848914c6583be00ab5355d71e",
            "33da76825dbf4ee88c81e4b577b48534",
            "7177453e6d814c7bab974eca2cd3d871",
            "4a2aac52f78a4eb5a6ba5d6a7b053888",
            "fd3c69b32f654b7e961488f0f94b8bb9",
            "cca7cabe84e44fc180a599e1f2c4a7b1",
            "4e34f661d5ed4db4bdf2e33e1e24e1ea",
            "5d8b111d6b7540a7b05f47a051f474c2",
            "de77abe353d441ba819160fa01df8db7",
            "72e461d3686946fa9240f446b9a960d9",
            "479ccf5077844108a93c52d913c48451",
            "a98a47009ffc463fb94f6f997107e254",
            "f86883571fe64a08b718d344cdfbeecb",
            "8d1768a152ed46328e2a37628242040d",
            "6c33f70593de43a5bdd831bdbbf7b3f8",
            "86324d9eefeb4d54a5b53c8180563c00",
            "22b8f8c0ee5d4891b4e78624d46aba17",
            "0b860325e5614bd494b577a25a355e3c",
            "4a071facc602459b85005b945fef42cc",
            "dba8ec7d439f4b3ca93c2e0def263eaf",
            "d5805a1851544103b8e649a19d288c8c",
            "a8583c77393145e189d817cde3d69d54",
            "d5b2d2958e424efea276ca4ed616092a",
            "ebd810658f04443a87e7452c979c3ab8",
            "7573f7ff9b59410ca6dc405471c1e82f",
            "4bac27ee3d764e9aa5fbc894d8c503f3",
            "a1cbbc7bcc784038a56749a0ba233edd",
            "703ac81f6fdb4570935b59547a5b6add",
            "0f0c62e95c794faab9a65293a2d75589",
            "f5ec7ae688504cabad13bb355cb166bc",
            "d1d77e39fae84d8a8ddf3bb85388403a",
            "0aa739da6a4143ab96e47b7ad6cddcf0",
            "1853f25963d84cedaaa3250fdd0bf5ee",
            "f41a90dbdfd0417582582eb734fd0c8e",
            "e42a9440e73f4be8b983d540c217299e",
            "103741c78d1841fd8e8b7e9a3fd15552",
            "4382effb44224d83a557bee306fff37b",
            "3498e57a01cf4f70bf2561f7a30755a8",
            "d2fb149f188a4e0ba2068f3e42efc4ca",
            "4e7abbbf5e4b49588af7c515133c67bd",
            "079ec1d652bb49f0bf95024a877789c2",
            "511515ac7d37447a990defaf46f26170",
            "8783dd6d1e3b48e4abd865c74a28a3ed",
            "17d5a93081d64935b6f438e9071d049d",
            "50bbd5276310428aa25dfd7656589f9c",
            "9bd924f332254bbeb48669ca23c7785a",
            "1d1199bd59b74980be6761dd155a8a35",
            "b32306d7cc6e49bd862d9b64ddc02c61",
            "d6824f37cb3f4f9fb6bf4a53275df1cc",
            "5a7abb5422724920901ef60d9a0d1303",
            "1d71594bc2a14fbab64827fc740a71d4",
            "41e1217ebc7845029f2a81dc8a638c91",
            "c31c029d1df6432f81fa6a0f4c88a98b",
            "437783610b924bce998666c4c95e84dc",
            "38fa2dfe738044b08c651080306d0dd2",
            "000fe794568244bf9f827e71d3051cef",
            "669ceb3dc5ac474286df1360a9ddd4c1",
            "51608ef6094048fab17600287cc5b6ec",
            "ca52b2eb0c9b498a8621522c709d044c",
            "b75825dcfe9d486cb74b4a3c77d78be2",
            "8f4a93436b164435ae5c73505ace0133",
            "75d6c969aad14150b1f7ad570061a1bd",
            "da08a525046248f6a3e3870864a5ae1f",
            "4577272c151b461c85a12d9fadce4a34",
            "b6448825b16d49929a16ac1053c62eb6",
            "d353afbd2a784edfb2e292db5ca7f57a",
            "19ac07fd80c640fea7a7fd2ddbf11424",
            "77da6ac17d5b436bbca0006569f1c39f",
            "534ab3e80e054ce7b915aa703567191c",
            "12e2488e83b7455cb4c4b86a45a95350",
            "9d2a8d25ce984042a4bc3e8d5287f3c2",
            "e1900feed4df44d8965501fd7c0ef39a",
            "9b14ea8fb37241aab62218d7dca20b4b",
            "cba0a00c0b2849e28dc3deb5b23c3c42",
            "50992abbf8b54d9394071afbc03baba7",
            "28278a2e309f4f318716ca2ead661527",
            "23c1e658d23d441693453dd86d1f013f",
            "2fb1f8bb86c3495cbd1160a88bca186d",
            "6a0dc82e280b4214acee02d3e1011c8f",
            "a46b7f9208864234be6469d462c90476",
            "5d1e84da0aad4380b93d654ff235d2d8",
            "41f8771f72634c7cb0bf74f7e05d6472",
            "a0fb84c7d5c740c284e6374b4429bbb5",
            "b0bede0095b9425997955d3e51785246",
            "6f5d2cce24544028aa1d1b66b5127046",
            "cb7c30c88e784a058dc0f3459d50a0bf",
            "318b7ac4584349d6b1a3af4aa850bdf8",
            "d0bf675e5b4c4c8f8275040c8c00c900",
            "2c84bf1d694a4248be257e6ba6f4bef0",
            "c8c791be456d404fa64d11a6d73c5951",
            "a8f791fd7bc44bd0a9b24da209f559d9",
            "ac62d8eeb1c3453ba1141285c10e20ad",
            "30a374cba722404b89844533097dccbd",
            "b845d5d92273466798cdfa455874015c",
            "ffa25fa247114459a387d88d2c06a198",
            "e106f1148f2d4770b3a08727434e2365",
            "bab2627e14cc415987e066138107402e",
            "5c50471d37984eb7b2f551719af36dfd",
            "2bd544bd29a24e2a97aef647d3fd5f39",
            "719d4afad13f426d9769b7ba54f01566",
            "b32f2f70b0fe402f9b315a7c1ed291c5",
            "d06db5a14b894ad2bf7989f22087949b",
            "9911a0d32d604fc0ac5d58d4e9a86286",
            "18a9073eef554b7d9feae805f0dab185",
            "515a526237f944bfa191014aa7a10938",
            "9d6bce90f99e48b59f37c5ca4c20317e",
            "2a9ae93a59dc4f1699e718b4599ebdf9",
            "33e35fc28b63440ead6bb5c256b0a43c",
            "5357745df572456196b1d5bdb0ab570e",
            "6ea6a0572f184fd38c2ebddbc61c68c7",
            "f2f06b808c6d436ebf07486b73983c13",
            "34f209c3c7664cd292f44cec213d6300",
            "1f344b4a59c74d95ba79f032ac5bf9ef",
            "cf8b65b9bfbc46f3bae732ca74c3ae07",
            "0cb6745fc365431eb734505bf777bf8b",
            "eb3b0a6267c64d9eacba352cd316a35b",
            "6480ff201cf04d8aaad507c98c21f3b4",
            "5e3805e6b1774274a56018b842ed5df1",
            "160c28b28f8c4a4699a6e59441740740",
            "c513134430d441b39859332e7d2e043a",
            "f040031ebccc48949acc1d8c5b4a5ae7",
            "2f26b9a8eff74d71b16d16bc44408d0d",
            "54c9b78b10204a34b474ff657f9bb4c3",
            "524faa54fc434d579bd5d00bb8137efc",
            "132ee6c3274a4e06b0d5f3507ce227ed",
            "612a3d9ad18a458f8290ec4f1376ef66",
            "bbfc579e7cf446a0a006e5084b165f3c",
            "04bdda89264a4b11bbd8c4b3898ef1a7",
            "dedca6fc4bbd4b7a9d2c645b2f37d0a0",
            "2b79b3f6999c43dfbc31de663943565a",
            "9e0b5937af3341df96aa55da4bb632f5",
            "b40497e1f4f84adca63b7fe23d326a0d",
            "62cd8685d3394ffeba25654ae3b65fb1",
            "51a8225fe8e947bc842e4016ac7a4393",
            "fe6157b008ff4cf8b6e0798bb5ca3069",
            "c5ef5c099a894e489a21f9cdfb441039",
            "c7cc0bca78624f1da09fa5a7079abe42",
            "330ddbdc0700473cbcf321a54daab170",
            "8c7282d25627469bb53d0700c236a940",
            "c64fc4f355454f098dd2028ce566ac5a",
            "d59a8df863174d61a43b0a1360b8bc28",
            "68336a9a7b2a4325bdf5dd4f8d1fa4bd",
            "67b290e9ede7452290a75c58323c2656",
            "b7d3ed5e977a43e3bdbb110bb92d2fe4",
            "91adf204b9c24dfe9375c9b013e2af48",
            "9208d9f41ca54c2fb0b4bc7085b04f8a",
            "923730fdcec9474d8741166aa7becc42",
            "06b330d6dc38420c85095d81bebf667f",
            "db40204bc7024e9aab329f5f249c3664",
            "029efc05e6e342e6a22acb1e6bc7cc2e",
            "c6518ef5d822413cbb7349b70a0017b8",
            "a397f64d6e50495d8e87c42b9d3d6907",
            "56feeee6b4f24b498d57c6ab85cb9268",
            "d29f858c6b744719aec3fad4c8cd89aa",
            "1866c862d4b64579b49d94812f7a0962",
            "1ff59146fb56410d923be1ceeacfbd6a",
            "3e05c97424214feea6bdca19bfef4be8",
            "4a097902fc2b43b4bfc4419aed7ef993",
            "6e12b8eb62664c018e33386a68a452a3",
            "c05b3fc2321a419f9ad612f43e4812b6",
            "556267875674443c9078bffde36f6de3",
            "ecd90952f4664c94884b65b0023d2cb6",
            "57627397826d4dc091117c72aac9111e",
            "d0bae6d568d64745b5d8291598fd0ee2",
            "22129d2de58e49489ca5a02d0eaa484b",
            "3c73be2730cc4b2aadedf95e50eb3da2",
            "4b792cd4503c408fb4237e2e5d6421e3",
            "0888bb3641f546e4b115ac31c92b9e13",
            "40652498b585484eb75dc52f2eadad31",
            "6d2498721dad4424bb49ca9fdbbd012c",
            "97c4aad742f14606b929e9244ccd7243",
            "b8902dbe31324baeb5825509a24d56a2",
            "98a12223064d4c0a984fa4a184ea5f29",
            "6d2d284ef0674c39bbc7c6fbc20bc09e",
            "f17e012ff8ca461cb098666b9cf4a904",
            "74978a860b164d8dac6e92524f83cf8d",
            "54e02e3a830a44a6ac2dbd7f0ccc743b",
            "be37ba0b66e54aba858548a70a516c7d",
            "c1789ae01b504ac4a521e146be1955ee",
            "a13fc7be9a514be586151badd5ba9103",
            "87a1a263a6664aa3ab85cf09795bf9e4",
            "c6b16002ada04543a0238d8fd2c822fa",
            "50abfa93b83a4a22a629f9ef71fb131f",
            "6072bc76a4ad47e298c7280e682e4373",
            "b736cc998298455f9b31569c3e0f0aa2",
            "41eb0fb905734af7a59acc0360ec00ea",
            "aa2b03ae99da4c40b3709ddc20c8166a",
            "87a0076273f54a0e9a8cb6179c4526ca",
            "560ace7722184f04bcfae73c227f1779",
            "66684d7118c64125ad4fd51a3255f213",
            "ea8f4eedd2aa489c97cee370dd42b90a",
            "fb1afaaa6fae4e3cb4f5c6ca62d83769",
            "39055df5b0fe450d9e86d4a6e534aafe",
            "2d85265359ed4b85b9a4c1727acac491",
            "bfa428cb2b8c482f95339018ab0be88a",
            "8514583dd2bd4991981cf9be81f21236",
            "86b2f252d0b8486db9cd817935299cd5",
            "18d4429ae8d04a19ad6bd6baf8a0d786",
            "a988ea4bb52442909101a5d1d97dbc4c",
            "3e6db1d5a4db4778bd31afdc0cbd2f9f",
            "c3e44771f67e4564bed1465c03a179a2",
            "7a0d947567354d0794d0fde98884af06",
            "d7cd92d14ac6452e9af5babe201104a5",
            "d3a0b0e9222d40adbb3f8af293083104",
            "7f9489ee54a24342b6ee2cfbe77af911",
            "4f779e1c21e24b64bb299a9cee0f3942",
            "f1a3734ba78d45db8fb69fc2e12ad4ed",
            "c5ea14ecd4aa44a0afdbc52e7ff95d9e",
            "63979b6c37234bf3908d35a640207c43",
            "526247c58bc642df89fb9da785d50960",
            "92c6b40f251b408bb278a3ea7968d2cd",
            "5636ac0a5906449c8e6d017f4ddc5c2c",
            "9d861bbe9132408da47162bdea124230",
            "f77d0c387fee4beda1fbffeb3b34d60a",
            "a30a16d9bfc74635b3896ae7c38e9332",
            "4337be2f62f943a09521c7a26c355aa5",
            "c353066172bc4931a29296c7366c56e7",
            "61bc07fdb0964325b48deb61e4846c0a",
            "c521414705684d7aa71abb0b43bafa3b",
            "ca4b7ed78e33490780e7396073f1a98f",
            "68564ded1f2349a4a6a41119aac68bdc",
            "d4d086a5c4744a8e9ff2f047981657f2",
            "0ad1f5f52afd46eba049b648b30fa2cc",
            "bf1fc2d271f944bfa601d9024039a2d8",
            "5fcc210b1c4a494aa645692bcecff55d",
            "621099ba31ca43e7bcd2a4273a120e1f",
            "82e94a923c274f5bbe0f31c06844df95",
            "4e1d2018185e43f3886af17a7fb787c4",
            "9ba8bf8e38564b1a8bc0b126c545d08f",
            "b3c2acec02ba4bc58f15a240bdfffdaf",
            "e5d8cd31e3104abea43f0db917570be1",
            "0016c8686d4847328f1ff34df734c54f",
            "a95f796566de482d9e3900cb0ecbfb3e",
            "d9d6dd95727f48f08c5dce5affc91e2a",
            "8f96d01b983e4eb6a5b3dfde64cf4ec1",
            "db6883eed9d1461ab66970160cb3b991",
            "b1f73dcfe52d45f2a02b01eb4eda1c29",
            "306e8b896d184b5ba89367897e30bec4",
            "c54cad86236a45dabdb895824bdfa835",
            "9da1e00c6db147608a83d877393c9c18",
            "ec9d1791581145cb8637c9848cffeea4",
            "259ed8e612d34787b6fb873155c30e65",
            "6f38202275df40bb909b4aeb8d0793ab",
            "ba03b5fc4e724f7b8f8ec78da7ec18f5",
            "accc5c0db79a4987941ddc9e355b995a",
            "53b193165e5e4314aebaef4cd1f12b15",
            "3fa413a1bfd4417baf846f05acef3e58",
            "c057fe87cd7e499e839d37fd9722e38d",
            "a3970a27d46248268592b3b5ed019372",
            "ff8739df7c024437bc41619bb4381eb4",
            "ee28aaa258014ba993c8973b13423117",
            "6a19f6baf67a4db686ad1bf7c410cc6b",
            "15f05d70c15c4cccb7a4cb38a781bcab",
            "a08a68a1fd3b433a8b00e4cef03668a4",
            "5308b0f5f2724c38a2ab7c487b59cd7e",
            "0501a0553ae043219e1609b6931a5e83",
            "5bfd55bd18524b76b0adcfc0a51064f1",
            "c6cb11bac5854425a83a281b6c7bee40",
            "e6585bc2d7e54c4ca599c57d4dc1ebec",
            "89d43af0d98c4ecaba8921e68ca0dd0a",
            "5de993e4b59745359da7b6107c510c11",
            "40f97e91bbb14c13b4924896b0a3a1a7",
            "8168bc29ea014810b261b4e81bb22325",
            "761e61baf2954501a0998c2c47e4ff7a",
            "cdd4c15b727e40278ce5e51a8fe87fa5",
            "c07a2d864a8d4dd18dc08060731d677b",
            "579c7a404bf941d9af5faeaeec446a46",
            "5f8b0bb6eb2d47b48c4956048a250eba",
            "719705c5dfc7452cb2d7a39db02505ea",
            "283a016c2a564551be402df04b1e7133",
            "f4be9bede37f4f9ca2b5cd943c23b080",
            "d93311c0e13e49c3956c22f0644fd6d5",
            "45762ebbf16a41fd8b9422d64172997c",
            "0817f6e70b1b4e2ab3c81e4d9115232f",
            "7e54af48ce34458ba55d885e21c4ed90",
            "4ebbfe68f6f347849be963dc739849b0",
            "2452c22f52ff4825883ce74459d20bdc",
            "93caddf6929344b697bd008925e41531",
            "2afbe88a82c64cd6a5e9cdaedde5bc0d",
            "b5ee04c99ccf45918eca588a7de3d769",
            "ec075a1d48ad4dfdae38caa293d19eef",
            "fc8a7c9a47024357a17a19e28f92618c",
            "b70a27295f7b4057bb62ff078bd8479e",
            "57de1074a15e4df4be5d44e34d7b3635",
            "29c2a58aea704f158dc4d0016dc81e3a",
            "0436ec92982a43c9baa25f4fd63530a1",
            "ad278e2e027a41cba8fdaabc71eaa705",
            "9e9a53bfb9e24123bbd7aa690b71eb90",
            "f48f69df0ca24cd3b708ff32ce7e0bfe",
            "3ddff532bd7b42678866283a48ca54d3",
            "1fbd1d7b8d4c47218122250c978f3a4f",
            "8da9b579141742b58929843efa721cbd",
            "09e19730ec63401a9c0cc8082f23fcc2",
            "6d6764b90b7142e090fc0079ff50c2e1",
            "b90eff0fe77f4f0aad9130c2143d5704",
            "aa7fb827193c4371b776ce1ce3e24909",
            "c239dcb7b4f24e31b7692f6f74df1e0a",
            "3f39a2d24dc94de8beb6cba206d295ae",
            "a1e9fce8928146abb9a125c1e2320825",
            "dab001cbf806449eadf38aa2f6a6b589",
            "32e9cfb73d2f45989405967092c1366e",
            "239a8f70f5754fe3887d42782d7209e4",
            "941ede2977f24a98959d42c8683bba4e",
            "9667e6c383c344df9d00f1cdbeaeb026",
            "e7d80fd6ea4b44ba8784c81546c8f43d",
            "4dfa41cd13f347e08597e32b8176a2a3",
            "281b1a2b3311452a8c7c8fcce9176381",
            "3798a9dbf6444d8facbaed8615dd88a8",
            "d57c198a04b844808f8f6db52264ebe8",
            "f90a158079554bcaaed66cd8c833d30d",
            "ce3afcd20aeb4f87a7f380ae45b295c6",
            "5116b0be8f944645b01b81248f75ce4c",
            "0ef35cedaa4c4803b739e131d8d49da7",
            "31e1db42a9cf426eb66a0052678d2f1c",
            "f8da9eed88924ddda0c01b413af7d017",
            "55195a78a25c467abd490ecced364414",
            "a228890d4be24c69ab9aab78a9e63931",
            "49163463a4db47669574d966c3cd9d9f",
            "ba684244f5044c3ea933cfcabc1f24b9",
            "e1f0af3b976847cb810bf0d298ce2f79",
            "26b3fb9a432548848ecc7c176c776f87",
            "b2d79f10e8574be2a04bbcc9efefddd7",
            "4417541043e74324ad4798c5df6d42ae",
            "ddc8bfb363624dfc87a29c4388af1a7a",
            "3ca7073eb2ad421d83ce982ff4d4e186",
            "3ff00ffcee064231b9a498e5ebd1569f",
            "a514657062ad45e9940bfa3f8559f394",
            "2eedcc041d64443fbb54e0356a91a49e",
            "1ec0c146fd624406897314478f7dcaf9",
            "5080543cd10c4873bc01616a4cf981ba",
            "cf0a7845422445a1bd9542e075e89f43",
            "0bd19944ed894719a31540da80b0f9a7",
            "b6a132af914344a2b9047a8c02d858c8",
            "ea43a709ea0a4ea898c648b95c4d6764",
            "37d59e7d9d4d474da8988c563f62bbfe",
            "23820bd2bdb4476997be41394af1e22e",
            "f5b44f364e3543edaf8e8ca7cb8634b3",
            "c1e5029248714bccaab373720a1d898e",
            "6583f4f7b7184cb99da9db747fd2c2fb",
            "b5ebb24d968c49ec9614d2f6b5129d50",
            "00a5462c7f334201bee1012c2d033592",
            "cb1ece66e9db48a1b1716ebc6d729a78",
            "dfb0ea707b1840528d7ebfebf6915631",
            "1250e17efd0741c69d10b76cae2a7bd6",
            "d1b654325cc64f4f8d80457431877d52",
            "c4a507201f09499cb5048d6e4ae61727",
            "8866651207f8404ca6a5b0147a7f9e04",
            "69f42a75bcc94307926f742a714833b7",
            "885031c123b44e36b3283b1fce00e28d",
            "7f56c73ac1334bcaba66c99e3f1206d4",
            "fae86d993bd8422fb36071465f7bb6f1",
            "d9638cfcdec04af0bb5fbf4f5bbedbad",
            "fb357535fa134f4893db5ceb5d8d1ebb",
            "6c655d63446d4e588086e46f2d42e1b0",
            "a1c89e2bd3c844a8b77826a7aefbebe2",
            "cc9433f41e174ba9a01e4a05e4137949",
            "a089c438709f45b981156dc1234e0581",
            "1eb5da1593fc4dd9aab51fa2fb34d4d8",
            "3b8c380fee834afe87423fbd6e43ea0b",
            "4f5e048d0a4d4c188cfdaa0ba9f85872",
            "c1bf91ee13434db29e940cee2fd882c8",
            "de0e0e357b384f01935a688887a65144",
            "eae5a090b1ad422b8c33181a1eb7deac",
            "ed7c628f78fd4b0bb61b013a456650f3",
            "7327ac94ea664b649683fd97cab63e90",
            "e189745efb3045c18221c16fbae76ff7",
            "5bf53264acb54c6c8e47609b10e13018",
            "57f4a4ebaf3549de813b04e2f5f61bd1",
            "e65b0b9c46264a5a87f4f7c58b770fe4",
            "5307a5f56b4b420ba188062db0532bad",
            "3752155dac924bf098241e4a98023644",
            "8c849aad66894fa0a2bc8423fd8aff12",
            "521187d6ff0b4b19869d5886453acf08",
            "6f79e74fc614480a8c6e6fd6dc8c7288",
            "5a3998af53d84930894f5aa572abe60e",
            "75d4987169464b98841234ef289bf49b",
            "12805aa00b9d4f37bf5120164c66f06f",
            "28ee39049cc64286bd2520d028c3ad08",
            "1e9f88d133fc4b52a43900cfde28152b",
            "c588f23a8a8e4797bc2044f38838d368",
            "57417c4760fa451298576253d7e410fe",
            "2abb54548b3a4fbf9cfc22dd565406b6",
            "4ca813056207461aa65b72ab5a7c53bb",
            "5f60c5ffc1b440849fd43579b3c859bd",
            "3039262fe4964e30aedf82cbbfeafb32",
            "ddda9b855e5443b99461c1960c2d177e",
            "9fbf8a4646c944958779b6f7db50e299",
            "0c166e19881949cd841ad5cd1805f373",
            "f392180150bd4b54b2a3ab1954bd3536",
            "fa525c09d98741d29fc7ae8fe7ce8450",
            "ea4aefb041684c6baa88457d913f982e",
            "0e772731ac8e401a8fe891f9b631bb3d",
            "3d778b5064264ad99d79e6811216b493",
            "0a927ac7b90d4cdda91f92b2e7a667c8",
            "9f643d75a63e4e8290eead6e27c59b2d",
            "86b694bdd68f4149959429c73ccd4172",
            "5840d6fd389549bd87a600a59252c982",
            "8b311e502d49412d8d65fe95f9a275dd",
            "d6e26880af014a989828face1bdab1b4",
            "b80c73e71a6b44e3b93f3095af0d51e0",
            "93fa5c2132494f17be13ad3a2fb99e89",
            "2691e58e00ce41e08ccdcdc6e66ca50b",
            "ce40a687ea7f4c3fbabb81ab2327a8a7",
            "671f5f292cb04fc3b138e8989111cb49",
            "fdd04cca5e784bdcb34a734aabbe1b1b",
            "8045b2bca91b46e894b34db07a1ca21a",
            "58e4e10d71c848e583dd5bd706d10f7f",
            "eddf04a70ab04eb08420f66c24705816",
            "11251aa9de294b328e23436ac4e2489a",
            "f34db8c2f94a4d1d86f23710b42e079b",
            "7e3531488d4b44f29882268f369e8717",
            "69957687d25644c697fb96b4e428c745",
            "a8797afed8ce4f9e801555f1b4c54efa",
            "11ae9b6264b54d33b8b7452267f81565",
            "266d5d46b0bc40b9897b92e4482a06fe",
            "1c819c61fd7e4b6aa08d120359127553",
            "67d69ed6f8364137922f60631692ff8f",
            "6371c4d9398049099cfc7107f15ffa32",
            "ab675c7bc8ae4ebeaa0f43d1802cc7d9",
            "84a07a86ec524353a692582139494011",
            "1a525764952244e99aa6546088354a80",
            "cbafc032b0b64658b36c4ac4aa98dae2",
            "3f77e2f10dfc419b807b938f530d7430",
            "f2af7d552c054a91b27030b25deef657",
            "5502ddc71a2b4b6eba4ccd7e27054f6a",
            "b0002c41899642a88e4516bc74aeda05",
            "ff2f32711b6649eda1573c5f87959fb8",
            "58d1f54c43f14416804b4d6bb9694df0",
            "67feb491c8b14078b3aca3b007cac3cb",
            "1c28349bffd64819b7789a73ff0debe9",
            "d73ab3342c8a416e9e598a271417f1f9",
            "68f29859d66449718bf9b3470df32590",
            "84d5bc30b9cd496b8a63338548445298",
            "ae9c459d2f07429aa8f24d2a24d407cf",
            "9c12b7fe72ec43faba5f9390a177e28b",
            "3044f18c3cc54ba4b41922b4cdd50911",
            "49b6bc0b4b4a4fa987c4926d03c13a52",
            "b8e9aa5311514742be6cd8aa21130bfc",
            "51a84d2d2c3449368d56a08fd2034e12",
            "6f5f9b06719b46b8bd2792be28122146",
            "2663328a851441babac62c4a840f34e5",
            "b9f4a5b0785646b4bd1f56abc8d7915d",
            "e84461576a0a4ea09629531d6c96d9c6",
            "8e8e9b23ca5f489dac27a730d30c7e08",
            "650f450e537f496e9a4caf9a3b138631",
            "4ad222b140c34244b8f10b6544b1c246",
            "d10b6bb1dfa34b11af818f0937855d83",
            "c003d32f2f0a49d7bad779ad64e5aac9",
            "d62638ff6c5b43e3ad61025f79fc6c4e",
            "aafc3bf22dd446c2835f8b1fbb252096",
            "fbe9af2725384c97adde053da902cdcf",
            "62c9f9cee3534652a3fff802357bdff6",
            "0ca69da7f85042149d90716b6f540b99",
            "b737de80b9ae494babc8f934b8b0492d",
            "444290c58e0f4bce8d3d6f1ae927510a",
            "7790e444a36e4cffacad65c0f212b820",
            "50731e446dac4685bbd83c52e8762a13",
            "212c709f05ee42569bcda442c1e80c71",
            "2af3767b7792438587e09dee17c76a92",
            "938ce2fc1d3c47278ed3c52ec1e4d997",
            "ca152a61c8d3414d8a736e864a047479",
            "747220f540c94b38a4f625c5fbc9bd39",
            "79db61fefe8f4e86ab9d9bad08ea1289",
            "698bee44a23749679440e395185b3e1e",
            "06f2232c521447d29461ad8eb87e29a2",
            "c1e20cb9e8924d60ba11c51e25015d32",
            "7414f75adef5496ea364bb5676c6daa1",
            "05693ef329e44df0b8d44dd79528b498",
            "26aeee7cc4a0480abf3ac170ab73b0a6",
            "7f4f6dedc9e348da9af123a83f0b455f",
            "74c4a39f98244740885911776b483b82",
            "e6f87a26069b49f5837dc6d10ac849aa",
            "4561cc99742743338caa4094b51c7c50",
            "5691b5b0f7c74f9c84a31cab70df340e",
            "a383b6642a08419fb4305abdcc0c3ff1",
            "ae89b272518048bb8c21d7968228be4c",
            "badffe4d099f4202b408160d465ebcf1",
            "e93d7a406e844ff68082f7fb5b4ac932",
            "0be62580d82c411ba896fc897e84d74b",
            "57c6c6a256874e04a05e2374fb1545d0",
            "03256f9ef1cf49128e90c1364129bd55",
            "504f518f7ef2410789a73c74f7733169",
            "c76f196fd7e04d8da125cde0a80feac4",
            "160ed52d24884da4aa3afdd5aba93d73",
            "1056edfa007848f4bf626f781862cfab",
            "c262b7694453436386553a98560ca622",
            "77e43e090e864c2cb0473a48185c5693",
            "797d8184904c486e92bf3078d3a6d54a",
            "d87d5be2cca5470cae8b752f923ba7f7",
            "d70722e8dcc34ac899003d87f63e81cf",
            "63a8fe7bf8d940319a318ef13ba8ebd2",
            "c6e3bf7deaaf44be8293cb23fd4c8f6e",
            "a006596e8b2941ed8f76f5095729240c",
            "5b7cb7e5f0844cc8aa4ee652435ea0eb",
            "17af4813fa71449cab6506615605f2d9",
            "f053d7e0be4c4a429351bfff1438967d",
            "cf94f19204c54167a7a4d26cc8ab71ed",
            "fbe1a02842a0446abdc6ea49ce49b8c7",
            "e4716b04c83a4b638097548ea2502e27",
            "2d3e9d5c3e0f47e2b51837cba17a2926"
          ]
        },
        "collapsed": true,
        "outputId": "2def8405-7d3b-4efe-a948-df5e8360c39e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ddc2d294ebd43b79391dfcc3c785672"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a74f8cc600e4ceda64082369847fd7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2c60088bd8048129fe2ce73ec97f6d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "499496d77bae4089a1b6df207332f5e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c4f6cbd552346f297e002f29b98d32f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68e1bc33627e4416b1a294d4e8b40144"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "062b635ab68d4218bb68dda661891df1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac595e74747149b29443c9114a2ba7fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d6d571431de4581b61337d5c20bec83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4633055494184e33afa26ca8aa859a90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce4fc5e157c2464aa2f4338850d963d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55fc7c6434b84f67be37116ae5d77f34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20668c2bec76429fa9f5530b6644b342"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26dffea670484e4dbd5e8d75d831a2c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7310fbfd78ae4644b7ed644a647c3912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "162310c3d86340348f39de7f23102ed5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8688ed3a904b45cfaa326de4c190c598"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "add55f6981544feda1a1bd9dec296285"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baa93b567dc1418781ce4478b3cc8867"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f38bb8f6c4c945e996486119edaba0b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a3eb2813d5d44eab23322f7ab822e23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "393aea5b944a467dbd28e2921e2d05d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5921526d48b841e28de008edab1cac14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9167b699ea84ddead1c640ebc6b272b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "147b9375e0304a80b29d88c96b09e787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "324a79c6fdf3465888875c87ba03ab34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cca7cabe84e44fc180a599e1f2c4a7b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22b8f8c0ee5d4891b4e78624d46aba17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "703ac81f6fdb4570935b59547a5b6add"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2fb149f188a4e0ba2068f3e42efc4ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a7abb5422724920901ef60d9a0d1303"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f4a93436b164435ae5c73505ace0133"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1900feed4df44d8965501fd7c0ef39a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0fb84c7d5c740c284e6374b4429bbb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b845d5d92273466798cdfa455874015c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "515a526237f944bfa191014aa7a10938"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb3b0a6267c64d9eacba352cd316a35b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbfc579e7cf446a0a006e5084b165f3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "330ddbdc0700473cbcf321a54daab170"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db40204bc7024e9aab329f5f249c3664"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c05b3fc2321a419f9ad612f43e4812b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97c4aad742f14606b929e9244ccd7243"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6b16002ada04543a0238d8fd2c822fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39055df5b0fe450d9e86d4a6e534aafe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3a0b0e9222d40adbb3f8af293083104"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a30a16d9bfc74635b3896ae7c38e9332"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.75k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "621099ba31ca43e7bcd2a4273a120e1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1f73dcfe52d45f2a02b01eb4eda1c29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/674 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c057fe87cd7e499e839d37fd9722e38d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6585bc2d7e54c4ca599c57d4dc1ebec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "283a016c2a564551be402df04b1e7133"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec075a1d48ad4dfdae38caa293d19eef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8da9b579141742b58929843efa721cbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "941ede2977f24a98959d42c8683bba4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31e1db42a9cf426eb66a0052678d2f1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ca7073eb2ad421d83ce982ff4d4e186"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23820bd2bdb4476997be41394af1e22e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8866651207f8404ca6a5b0147a7f9e04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1eb5da1593fc4dd9aab51fa2fb34d4d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e65b0b9c46264a5a87f4f7c58b770fe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c588f23a8a8e4797bc2044f38838d368"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea4aefb041684c6baa88457d913f982e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2691e58e00ce41e08ccdcdc6e66ca50b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8797afed8ce4f9e801555f1b4c54efa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2af7d552c054a91b27030b25deef657"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c12b7fe72ec43faba5f9390a177e28b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ad222b140c34244b8f10b6544b1c246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50731e446dac4685bbd83c52e8762a13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05693ef329e44df0b8d44dd79528b498"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be62580d82c411ba896fc897e84d74b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d70722e8dcc34ac899003d87f63e81cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (function for optimal correct answers & semantic similarity)\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_with_semantic_similarity(dataset, similarity_threshold=0.95):\n",
        "    results = {}\n",
        "\n",
        "    for idx, model_name in enumerate(MODELS):\n",
        "        print(f\"\\nEvaluating model: {model_name}\")\n",
        "        results[model_name] = {}\n",
        "\n",
        "        # Load multiple-choice model\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "\n",
        "        #semantic accuracy with different models\n",
        "        for sem_model_name, sem_model in pair_list[idx]:\n",
        "            print(f\"Using semantic model: {sem_model_name}\")\n",
        "            correct = 0\n",
        "            for example in tqdm(dataset, desc=\"Evaluating with semantic similarity\"):\n",
        "                # Get embeddings for best answer and correct answers\n",
        "                best_embed = sem_model.encode(example[\"best_answer\"])\n",
        "                correct1_embed = sem_model.encode(example[\"correct_answers\"][0])\n",
        "                correct2_embed = sem_model.encode(example[\"correct_answers\"][1])\n",
        "\n",
        "                premise = example['question']\n",
        "                hypotheses = [example['best_answer'], example['correct_answers'][0], example['correct_answers'][1], example['incorrect_answers'][0]]\n",
        "\n",
        "                # Tokenize premise-hypothesis pairs\n",
        "                inputs = [tokenizer(premise, hyp, return_tensors='pt')\n",
        "                        for hyp in hypotheses]\n",
        "\n",
        "                # Get entailment scores (usually index 0 for \"entailment\" in NLI models)\n",
        "                with torch.no_grad():\n",
        "                    predicted, max = 0, float(\"-inf\")\n",
        "                    for idx, input in enumerate(inputs):\n",
        "                        output = model(input['input_ids'].to(device),\n",
        "                                    attention_mask=input['attention_mask'].to(device))\n",
        "                        logits = output.logits\n",
        "                        entail_score = logits[0][0].item()\n",
        "                        if entail_score > max:\n",
        "                            max = entail_score\n",
        "                            predicted = idx\n",
        "\n",
        "                # Check if prediction is acceptable (best answer OR similar correct answer)\n",
        "                if predicted == 0:  # best answer\n",
        "                    correct += 1\n",
        "                elif predicted == 1:  # first correct answer\n",
        "                    similarity = get_cosine_similarity(best_embed, correct1_embed)\n",
        "                    if similarity >= similarity_threshold:\n",
        "                        correct += 1\n",
        "                elif predicted == 2:  # second correct answer\n",
        "                    similarity = get_cosine_similarity(best_embed, correct2_embed)\n",
        "                    if similarity >= similarity_threshold:\n",
        "                        correct += 1\n",
        "\n",
        "            acc = round(correct / len(dataset), 2)\n",
        "            results[model_name][sem_model_name] = acc\n",
        "            print(f\"Accuracy: {acc}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "rQXphdFY6eYD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (function for optimal correct answers & semantic similarity)\n",
        "results = evaluate_with_semantic_similarity(subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4dba0e486ef64a3ca5fd6c983746b8b4",
            "436584113dad4dd281d87ac9b1df38bc",
            "d8b2b1aef8f644398f046d9413580f2e",
            "d47ed8f33bea41ee91c728ece6aa7a66",
            "abfdc64b426748ada028a09ff0582150",
            "a7a21a2cd36c474182745461a77f516b",
            "70302f36fcc94cdba27095430da522d0",
            "c210f14805144411a53ce02ece2bd2d7",
            "370bb87e055f4e33bcbfaba524a7f4c0",
            "8a14da7f39104de4a2c025ab2a93718c",
            "d19c04c6716a4bfe9567a22c984928c7",
            "f5bd96009dd04ca895f9c16012f762e7",
            "f7a6bf2718764585a301f76b6e9e630d",
            "ccf0be4f094046acac87dd756117d90c",
            "4fe3f340049746a9bacf3530b9794709",
            "24158762e5854175b6ff06a39ae2d198",
            "e4f872c8e5c04292bff8db73d18f35fc",
            "05239f0836bc40499da59faa403c13ef",
            "9a587b53dd0f4c309a7c95e6e4b0e3d0",
            "568dbb17eb1b4b8b94b8fac3ea63f45d",
            "9d55bd3cd5204b9882e1d26bf2f60ad5",
            "0b606ed35d2e42159ddd6459abf90d53",
            "721fd1cc525a4660ac8f0d509a84ccde",
            "6a6b30b044ed48d288399e57cd0bb1b2",
            "16f689b26af34ec98540fc5c0ad7399d",
            "d80f7357961b4b2ab355edbeac16b65f",
            "b9339aaf9872465da42ac5b2597900b7",
            "9e0bac78fc454a669795c5c468d8cf92",
            "32845599701d44d98bb3c6db3c2d345c",
            "d5824720bce64beda0f0a752cd2c1dbc",
            "670081a3c09142a5a73d96848c7972dc",
            "eb3ec83a272c47c88c43a47b19a06cae",
            "26c6167d65b94e419e1a53deed9b0047",
            "fdb46d05755a4cf8ac484347b5c94527",
            "acbbf614ddbd4cfcab07093b67a57cb5",
            "00698946f7d040f6bb535b98e44617a7",
            "731e87a3b7544350bc47795c81606032",
            "bfa6fa40510a4f72b97ed315cf9b4841",
            "881d81b006dd4552854565da0577d4de",
            "c985fa48936b4a3b9d3e208e2b78198c",
            "1f4b2c3281964860b81330d82cca51a8",
            "29c46381482c4c6ca3a9aa79dccda1b0",
            "a387fade2d8441379cb04168f517f460",
            "cb13286b0cef4556ac22940f42823af7",
            "f835571ad03d4d06a685574f069ad279",
            "eccbef7c8a3d47e3b70405b3e8c8f15b",
            "931038eb57594f2db3663dc91b29ac26",
            "34e7e87413aa45d89f08b0ac7b26cba4",
            "74d791926e024ac79bfb55f5ba8f874c",
            "ddb98ea199da475da9f4f068ad5476fd",
            "2de3bb6381ec4a78bb5ee976057a77b9",
            "28d006a7795a44a28221a0b4512b35e5",
            "0f48a674c67e4a21b8950aa9c1e16985",
            "683d6b3140fd4858976b28f75f214b3c",
            "bf6e668b71db4f0485e4ee9233fc5aed",
            "98daa5f5ed274026bb5f660ae8943181",
            "9eca86a5e40a4f69a9cfc29588f17f5b",
            "3cc656e8b97945eba76f4780adf08b4f",
            "c49b9ccaa7f543bdb9227eb6dec3c701",
            "8612c79956da4ad685ff03d58e616107",
            "1038111feee74239be22aa2227b0639c",
            "9813e44b34c14efb929989cf819dcee5",
            "bf27b52d3fdc42fa9b9415edc6eb44dd",
            "2d88746c26dd481a87737caa52434e0c",
            "0126e8c9ac7840aeb381f4d4ea226ace",
            "eec9058f8f3c469bb69f53be9d8e7729",
            "8175aee4f89a49febc1222b98cd352d7",
            "509a9d0a139646b99686dc6340c4e0b0",
            "3dea75675ee4458c94b788de5ebee575",
            "df88e5f4f193401a8c40ddfd71c083c7",
            "b38893e3fc104f6ca99691fd810690d7",
            "1bbe7ab8817d456cbc476ae09c94351e",
            "b6e22b43997241c0840dd66fc988d937",
            "b4ee1cdc04f149bb9495a06b4b9bd189",
            "5fe686289737496ba3917a86cc395e6c",
            "8671692501cb47a3b55f22cad70579ec",
            "3bbc4707f6504cd5bb65098c35d14048",
            "99989ad6313c4f5e846cdad28347bdce",
            "3d562a70127d4fee8a0130c538c0df07",
            "ef5fce99f69a4f71b2868bde1eda8ca4",
            "e573ee9fba5a47d0bd6ca27d39661094",
            "bedd396774d24cc6ac4822dcc1a554fe",
            "73baa947a47f429191b55ef42db06d35",
            "3abb5429f9fa4dc6ae30df0d60df9f86",
            "932a576076a54801ab3c7faa358d186a",
            "24079e34a89247caa96402fca5071602",
            "decf1962ce5844bc823c79584fddd154",
            "696a7d50186d4f099af205a7cade1003",
            "4ec9eb05f8f049ba8f644fb3c578063d",
            "9adcc2f89b4f4055beba30a8b2d98b1c",
            "e93615bfe4914a95bba410cca14dda6b",
            "a54f822c530a42d48d153abec7614fef",
            "c30347588b004d9da40c5f8ee56de2e4",
            "c56352b62300485aa6756733631a58b6",
            "60bfb87c98b64c378b7d28532d703d46",
            "e9508b993a4648e7be6cc478a7814866",
            "da7b7aaf07b84bfa994352d1f56e4e4a",
            "17b798d210d64a2e9f65af6128507802",
            "4354732cfd2b4416a6f85c1e167f21f8",
            "bfcb392aa7b04094a4488f9084475a71",
            "f0c4ff304db84793985cb5e48b5b2862",
            "71e348c5882245bf926a92792b7e964c",
            "8368e4f171ac496f99cc04a0fb1038f6",
            "ef3e83638fa7484a897d59059f50d3bb",
            "84a9f6149a4e4dd38cb2b1aba2ee933e",
            "a525ed952abf4762b694bd0aaabc567d",
            "6d5c6ecf8fdc4429b09bc1d205af82e7",
            "ca305372200a45e8ab637a506d17028a",
            "9da4172becc848be819fe47b9e9b7437",
            "a040def5a1b84c65b4dc4241f6f8980d",
            "c64060f3d9f246ada46450d7879d305d",
            "b0c00f41ecf94b6e8632d60bf2e97fab",
            "36035f58d67d41a598af45a5f84633ba",
            "0f228b95fa9b472fad4d71648855ad15",
            "8bd4681a3fe1461ca8b90fc4f35162e2",
            "148a65c8864646fca22e5f6cc6510e8e",
            "f8db72e87a2541bbaab38821a278f8e7",
            "6bb321a0e24d4d34af99e9417d4db54e",
            "3fce72194a784e7da26e474a2651a0d7",
            "08348083ee0046aaa68d44487726d8df",
            "bd85597405be43b1b78f8358a9bf9415",
            "ab5c94b08a594256a4202bc26cae96ee",
            "61e03d36b6864ac0aea3adf3b4a92920",
            "30ba6a2c379f4bb286a79916f4169859",
            "b5fbeb4cc9c048b1bbc6829c74f82963",
            "68f02e692e4b4b0f81ddb4cd51e63f0c",
            "9b9480c1eb2c4d20bf92041f6f68940d",
            "546429c407c74c14b01983e1f6f5c523",
            "a5418ac2cbf84dbc88d04b7b9d11e37f",
            "1003902a0f5648a9ab7c10b1bd55142a",
            "d5ae2191e6144352a777593a31c5e153",
            "b31a6cb978b24bb5b004f1eedc43a7cc",
            "b08637dc9530465aa9c35e1d87075b8d",
            "6c71c835ef6145d4a3bd6fba1700a567",
            "dd4500ef4f9a4f4f96fc749a86f1ff48",
            "6180388c58994e3c836efbe822b41768",
            "55cc72361e704ca08b670365025fab9c",
            "2d932897086f40578f945941c3da2358",
            "c08be4b04525478ca4450e8ae049a307",
            "bc340a2bd13345a5bfc5b4d4bc776ce1",
            "bb17a9ffb3e743fd9272a1775d68e81a",
            "9535bb3158e14584b38e8be86a9e6d00",
            "0d5b2b54cf10484baf059f98e4890bc2",
            "159c2f04013a4b8c97d5bb98e7de7bdd",
            "22c87b2bf4b640bb9586f14c9a2d3a37",
            "428b0b97cfaa43f7a6933a4b0180dac5",
            "15a57ab372194b0bb56c74a5d4da8a65",
            "5fa919b68e424ea4b93c7dd46783c0d5",
            "b7dda70daf9f4c56abde30cdfcf2b6be",
            "57ea6b7851fc47bebb7c929f759a2839",
            "e7ba2090cf4f405a9bcc8903076e61d0",
            "25c664a625aa4f0caefc5051a79b066e",
            "a60d502c446347e5957b7c7a737f3207",
            "d5a135a0a92e46749d070bc6b7b5910d",
            "fb04103f52cf4b3690f8e1b3e5bcfb17",
            "a8a5be3c45e8436fb50c7995dc0cbd1a",
            "f821a9442f534e6d8f23bea300817a7b",
            "c57fe715ca0249f9bedd571c6556d7d1",
            "247534455cf74b3d8d48a401f13513c2",
            "bb78c64d517b40e2845a6f52525ba027",
            "e89d4c42ebd14504a989b3010363b437",
            "022b7b0fd92145e5a6de74eecd7c2ded",
            "cd71d9221da1412b91df63a21a78e5ab",
            "3bf1dcc98ad0495c893df6038ea0db84",
            "1a642062b3de436eb8830fb202630f43",
            "c5f49c397aa9439aa1fe50597a2d9b16",
            "8ab8dfd1151f473fb63890d9d6d09366",
            "9e88f97007e94cc995193f4da2cb373a",
            "3f1453ab950c4e57a2a8a35a7ddb7662",
            "79738ac9a719499c922eb86166b7edb3",
            "1092bef6664649929cc9c11c988dd78b",
            "7439dab5dcb142ee986262a76348a350",
            "6ed1395cab50470b8dfd04bf55e9ffb3",
            "62904662992446a19286a3ba03514b65",
            "23f979ab967241c3a55edc344bdd9971",
            "62b23f567ded42db889756f40da69c70",
            "11e6a65a91cf48c4a69ce321605302c0",
            "241ce23a67654164b456c16e9a29b784",
            "11d40b88d2cb4583b19f5d7eb34a39c7",
            "9a24203f8a264e1ab5547def5304cf1e",
            "b6d61d3021fa4796850763dee6af7af7",
            "e6d8394faa6e4467b02c76b5be2199a6",
            "a120b93881e849f28f2573b6a4743be4",
            "ef146bdfe8274ab0a1d993ccb712764b",
            "d2b86ad7f5314e0ca58bce1e898bff15",
            "bdfb8e9af7a349c7875d4f183e87900f",
            "72ba2aba721e4a9c9ffbfb7bc9d24a10",
            "0dcc622634da46f1bb869cd5a956e51e",
            "4b998148411a41749a768733f64536e4",
            "53852a8f7292458993434db535ec50cd",
            "9da3dc6eb41b4cdcbafe3138413373ff",
            "acf18ef853144dfeb454e7740f56376b",
            "fd1c9419ce264ba4a6d2fa3c800163e5",
            "6db74d6243b14b419d0f60b0e8e1838b",
            "2ad7458779e14f7abc0a3929722ba15c",
            "797019488b4a4b3d87fc97edfcff623d",
            "f1f054fc34be4314bd190ef162401681",
            "67c651a289b24e93a816a3e3eb60b224",
            "083d8431faac4fb9b3bc2efc4eaea31a",
            "1ac4d2072761439aa9db982821d76abe",
            "916a50c5e71a4d178c4343024d60641e",
            "624b15a98e014c68a9888481033bd5bc",
            "4279e7de9ffd4b63a97ae2b3a2ed0314",
            "b708aa7b4f2542988025df38439bf03b",
            "8ab85fde696d4deda703236d8f142198",
            "9da4cf9e82e54a8487b57a9fdf390bb9",
            "f5fa68921f014864824e69c95585fe36",
            "fdcae089f3ee41298fdfdd42c2b2f412",
            "69f37d18a3f74ae0a6812483a79f08be",
            "7ad204a4eddc4ed4bbd1a80b3ddfe81b",
            "878fb2891eb6412cbbc7b5cbc52c552f",
            "44c58421b92d484989bfeef5a4179264",
            "84ac7705e5d24a94a73a69f4868ccc16",
            "f8e3196e8f0d40a5811bf4009d1979e8",
            "7b4eb8bf308f4139820e066c6eb09cf3",
            "3e69ece98575471399473111d0729ca1",
            "5bae42e07241452580a9199e0b633799",
            "eb896aa0f43c4937bbd59f6745d2647f",
            "d8b5a32adfb54d46ac5f5a5cc67396ff",
            "14acc1919b3c484fa23476856336e967",
            "83d03a3ff8cc472abb7fa674eb863343",
            "401986176a324bb588df6fbd45d5202c",
            "26b08e7aca494af4aa217340afedddb3",
            "dcf0b05e32844fa583f59ec8079fb1cd",
            "83ffdb462566458ba47680dfefc1a86d",
            "ca98f38e7b814eccb28b9f795637b1e9",
            "cc5107feb80642e9a549c3752b21c10f",
            "c54a8d93abe74e569adc20c3f1a18d8f",
            "a3b76fff2f384afdbea33f83c00aa6d1",
            "1966c6d79884494189bdc806eeb08d09",
            "f2e987317fa244a6b59feb1da2e7a45a",
            "91dc41287a1b4e3db710657f050e3de1",
            "b3a4d4ab34a04160a4ae7c8b0cbdceb3",
            "0d7571a24bbc4bb0a4de943e859859a9",
            "1dfe4ee19874462f80a3ae4ed30fa900",
            "869aebe1721a4fe8b877b23565ff6a97",
            "7ade42898a7f4042bbcdfca37040ceaa",
            "a207d9778f80459881930cf9f91b7493",
            "08c95bcb28204c18b41a9409c2524d19",
            "db9dd1f7c38448919ddb012a5c555e82",
            "11038a1da1cf43b4810b4bea981deb6e",
            "e2dfb30a357c427ebf66778549dd4e89",
            "44a2e986830c400c9c04c32271e92480",
            "550680569bd245849b039bdff870d5c2",
            "7f9ac6eedfa143f08b2a394c0cf257e8",
            "b65aa548c4b84ad1a81df25e648dc1d3",
            "2d51b5a3cbb44ef2bc6c50d479e42b64",
            "b633fda7c9e841678b168539ab71d542",
            "bd5c0024a12c47c4882826b02f740393",
            "b8135948c14446d9a2a8a5d122baa957",
            "0c2699d6ab9946fd8705d873788b9772",
            "ce5555557588474386a81499a11d788a",
            "ee9c0b25ad4f47bb8b48f903be1e8c3b",
            "529f770bc10c4e4caa65825ae630fbdf",
            "715eefbb58084a1e8d64e4237f9f75e1",
            "f2ddeb7014fd4d32a992a52d4e7284ed",
            "923b9bdd403f41df931f56375293bf0f",
            "d6472132a8bb463c8a7059cda477f24d",
            "6c95fb5f6cdf416ba089023ae1f86cd0",
            "064bf16a090040618e13327a540dd4de",
            "78851788a24f40fd84f99586103ef9bf",
            "89ddc3f3605547f88e035321d6f0b6e0",
            "dd37bdc41c0648c0a68bd061fc299e53",
            "dc33e6215e18451dacfa16a1632bfe84",
            "4ca958435552481b88431646461048de",
            "071df5c2c2b9425882d0281add86610e",
            "f816e0c48ca84a2d98c1ec7b020ce879",
            "72f8184f470a40959d9152596bccb916",
            "d503e8462d2745a8a00fde4ec19d74f8",
            "0489727dc1d54d8ba485603efd440b68",
            "dc63685c856c4ad4982bb1f47417a6d0",
            "ec98dfb581fb46848807a1462003c8cb",
            "75d7943e76ff489eabb395291e82881a",
            "e5bdd88aeb5d4dce8256e116ec2218a4",
            "85e12474b56e47cf80a49d56661dab77",
            "91a918417f77470b950e10afb521c786",
            "c9b75b52f0b146a89a4e9c4201a1ce6e",
            "542f768f84084fdcb924741e382c7a2e",
            "545457727f8d4a349214482ec178c083",
            "b3a225d17cc94e6aa71f1ac2f22d6bf4",
            "091e650aa4ca4067aee1299fb10931b9",
            "b0a1d51d467347a0823bdfcfcfb36bb1",
            "864c8f5fbb4041a1bd75512a1b4afe33",
            "7453f6afd7ab4332aca45a4f8be98b2d",
            "e8f2311bd5c44c8b87ed6faaf49e4232",
            "4fe017a6ebab4593b9ccc837ff46bada",
            "36102e3ce89e44dd8a355e4dbbd16fad",
            "83d5c638e4584581ba2fe9233103cc34",
            "7fd2f3225cde4693af42fdf48877fb75",
            "5eb1d50c4a1949d091856516f10bba12",
            "f2225e7d2c994a9db49b837d6ae4bff5",
            "f2673e6e51bd461e90fac7c2c947a451",
            "55b40ea9741542aebd23f0b41397ffaa",
            "ec0b902d8013499fb01936ad1047e638",
            "216349564b8548c5a6276682ef630f5a",
            "18f83bed008f42ba8e8ddf1da9132320",
            "2ea622be174b41339d695498136408ac",
            "fae7094bd26944ce801fd3c777c1ba13",
            "2d1ef377d2084def99d0b2eda19c0119",
            "7737ab30772f40369d9404de981390f5",
            "39e49b512dbb4d7f8acb0a474961c960",
            "08bf77226b3f470b8c2ff95520679b62",
            "baf1816d58d14e35b91af20ee3c8e9d2",
            "1e5e8f4a34e9426bb6049db211caf062",
            "c165280564de4befb84c1099003b1726",
            "9a5c6d50ea134247a343c6d4d0fa7715",
            "c90c4c128f02488b9b4560bc8682179d",
            "2bcf64c61f2d472bb62dbbf9780d9990",
            "e5ab6a508a4943a583d492e485caa06a",
            "38100b81a3944adc95414cdb5f0c3f50",
            "07cdf7c323a749e0b391adc58fc236f7",
            "8f6832ff2216459b85f3433087234e7c",
            "f1b8aec1b577479b904f7f479ae1cf3a",
            "2b1be2c3a5984e9784739db656ab993c",
            "820645804da843bda5c3a545f2e1f2ad",
            "b382e72c183b4071b05419bd16556790",
            "663fe7d33026443e9a9427fdac40e41d",
            "7177dfcb949f4976920b0807d89d10fd",
            "adb16d503f9a40aa87f3267858bdab42",
            "bd8e3b77658e4e3d98cd356224aef3fd",
            "cc1eb9de55cd4c93b485ab7dc8ff23da",
            "3943b3952e0f4b439943a52eb58f35a2",
            "bf768c17bf2f4ea19d8fc2053b6f7781",
            "e60e77aec91746a48a3fcb67ee85c4e4",
            "bfe77ae601614335a1736c3415b2786b",
            "7c9410dcc7814d07b478943e73165535",
            "a42a5c4b91c3443484420a76a15c3537",
            "5b159b3c9e874776a08073c1f44d0db3",
            "bef2650f59f641b483e0022d27055367",
            "54a917d218c24ad8b526e8dc901ed286",
            "19cf1bc73f4f47009f9de92fc5b68fba",
            "38d1e9edc3af41879697e003833a8769",
            "48ded36cce7441fba3bdc0563b804ce4",
            "20821d2939f34081b6edaec6cd7e6ea7",
            "641858d00f23434582775baf78c13733",
            "514bff09bd11476db0ce176edf4328b9",
            "1841411a9d6a4046bf4a47fbd1b70b95",
            "ab4a184b1f074285b5e16853df6c68ca",
            "946f0b0a2eb04f208b62a358f4811fa7",
            "aa81d61b969d44baa532a331190add10",
            "43df6e9e1557466c82f3c72123bdc4cb",
            "7105f9579f804008bf6283ec8c6e596d",
            "7b5c7f5b7b0f403ea12d4182eeddb19a",
            "0c7919a0080d48fbae9c04becd3bf326",
            "1c6005fb6577435786a760a34b4c1a59",
            "40548bdd65d540b59a4538b7073426b2",
            "0f7376cff1204117aa81f68a826d9e71",
            "50797c524927423da0d090f7b91d3d27",
            "0699bc8a8b1d4560bbebd87288a34bc1",
            "f39eec6d9861457b9e61bc112e0d3594",
            "a6e40e089beb4977b60fc40f3ab3c792",
            "f7b2ae2bb80244bd96f46c1f93bb2a5e",
            "71bb14b8b2104034991b274582101bec",
            "79dc087a08394e8ebbb8a8e7ebe3ccc4",
            "4f76fd26e3354d5589d51cf9178504d6",
            "501e8d8da59447ce81b9ccb2f8ffdf30",
            "a0b5a5722bed4e2681a70cb365de988b",
            "3d3cfbc22fbc4454a58ead42cec34051",
            "cbe5ff7751f14c7e92eb4531ccbdd984",
            "223076477b0b42a0b8cfb896de52d5cb",
            "9774fddb297543eb86a121bdc595b4a5",
            "84fbe0f995c8423b80c2498b6092c3e1",
            "09527a8d69b14019acaf0ee7d99ee045"
          ]
        },
        "id": "KlH9TIMa9weT",
        "outputId": "c279d70f-5aba-4676-c8b8-0a0f74e8f7e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model: tasksource/deberta-small-long-nli\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dba0e486ef64a3ca5fd6c983746b8b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5bd96009dd04ca895f9c16012f762e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "721fd1cc525a4660ac8f0d509a84ccde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdb46d05755a4cf8ac484347b5c94527"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f835571ad03d4d06a685574f069ad279"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/19.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98daa5f5ed274026bb5f660ae8943181"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/568M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8175aee4f89a49febc1222b98cd352d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using semantic model: sentence-transformers/all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [02:13<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.34\n",
            "Using semantic model: sentence-transformers/multi-qa-mpnet-base-dot-v1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [02:32<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.34\n",
            "\n",
            "Evaluating model: tasksource/deberta-base-long-nli\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99989ad6313c4f5e846cdad28347bdce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ec9eb05f8f049ba8f644fb3c578063d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfcb392aa7b04094a4488f9084475a71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c64060f3d9f246ada46450d7879d305d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab5c94b08a594256a4202bc26cae96ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/19.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b08637dc9530465aa9c35e1d87075b8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159c2f04013a4b8c97d5bb98e7de7bdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using semantic model: sentence-transformers/multi-qa-mpnet-base-dot-v1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [04:24<00:00,  2.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.32\n",
            "Using semantic model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [03:56<00:00,  2.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.32\n",
            "\n",
            "Evaluating model: sileod/deberta-v3-base-tasksource-nli\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb04103f52cf4b3690f8e1b3e5bcfb17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5f49c397aa9439aa1fe50597a2d9b16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11e6a65a91cf48c4a69ce321605302c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dcc622634da46f1bb869cd5a956e51e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "083d8431faac4fb9b3bc2efc4eaea31a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/18.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ad204a4eddc4ed4bbd1a80b3ddfe81b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83d03a3ff8cc472abb7fa674eb863343"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using semantic model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [03:40<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.29\n",
            "Using semantic model: sentence-transformers/all-distilroberta-v1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [03:44<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.29\n",
            "\n",
            "Evaluating model: tasksource/ModernBERT-base-nli\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91dc41287a1b4e3db710657f050e3de1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.58M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44a2e986830c400c9c04c32271e92480"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "529f770bc10c4e4caa65825ae630fbdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/5.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ca958435552481b88431646461048de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/598M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91a918417f77470b950e10afb521c786"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using semantic model: sentence-transformers/all-distilroberta-v1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity:   0%|          | 0/100 [00:00<?, ?it/s]Compiling the model with `torch.compile` and using a `torch.cpu` device is not supported. Falling back to non-compiled mode.\n",
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [02:03<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.25\n",
            "Using semantic model: sentence-transformers/stsb-roberta-large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [04:09<00:00,  2.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.25\n",
            "\n",
            "Evaluating model: sileod/deberta-v3-large-tasksource-nli\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36102e3ce89e44dd8a355e4dbbd16fad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fae7094bd26944ce801fd3c777c1ba13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5ab6a508a4943a583d492e485caa06a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd8e3b77658e4e3d98cd356224aef3fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19cf1bc73f4f47009f9de92fc5b68fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/18.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7105f9579f804008bf6283ec8c6e596d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71bb14b8b2104034991b274582101bec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using semantic model: sentence-transformers/stsb-roberta-large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [13:40<00:00,  8.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.28\n",
            "Using semantic model: sentence-transformers/gtr-t5-large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating with semantic similarity: 100%|██████████| 100/100 [13:26<00:00,  8.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "WCNrR5nV18_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8513b8f4-41a6-4011-daba-95321ee02462"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tasksource/deberta-small-long-nli': {'sentence-transformers/all-MiniLM-L6-v2': 0.34, 'sentence-transformers/multi-qa-mpnet-base-dot-v1': 0.34}, 'tasksource/deberta-base-long-nli': {'sentence-transformers/multi-qa-mpnet-base-dot-v1': 0.32, 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2': 0.32}, 'sileod/deberta-v3-base-tasksource-nli': {'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2': 0.29, 'sentence-transformers/all-distilroberta-v1': 0.29}, 'tasksource/ModernBERT-base-nli': {'sentence-transformers/all-distilroberta-v1': 0.25, 'sentence-transformers/stsb-roberta-large': 0.25}, 'sileod/deberta-v3-large-tasksource-nli': {'sentence-transformers/stsb-roberta-large': 0.28, 'sentence-transformers/gtr-t5-large': 0.29}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το truthfulqa dataset απαιτεί μοντέλα με general world knowledge (facts) και για αυτο τα μοντέλα που χρησημοποιήθηκαν στο Β1 δεν πετυχαίνουν τα αποτελέσματα που θα θέλαμε."
      ],
      "metadata": {
        "id": "UyAer7bCKBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Β3. Winogrande dataset\n",
        "\n",
        "Το [Winogrande dataset](https://huggingface.co/datasets/winogrande) αποτελείται από προτάσεις που μία λέξη τους έχει αφαιρεθεί και δίνονται δύο πιθανές επιλογές συμπλήρωσης του κενού. Για παράδειγμα, δοθείσας της πρότασης \"John moved the couch from the garage to the backyard to create space. The _ is small.\", υπάρχουν δύο πιθανές εναλλακτικές:\n",
        "\n",
        "- \"garage\"\n",
        "- \"backyard\"\n",
        "\n",
        "Η δυσκολία της συμπλήρωσης έγκειται στο ότι και οι δύο λέξεις αναφέρονται στην πρόταση, οπότε το μοντέλο θα πρέπει να διαθέτει υψηλές δυνατότητες κατανόησης γλώσσας προκειμένου να επιλέξει μια νοηματικά σωστή συμπλήρωση.\n",
        "\n",
        "Για λόγους επιτάχυνσης, επιλέξτε ένα τυχαίο υποσύνολο 100 δειγμάτων από το training set του Winogrande.\n"
      ],
      "metadata": {
        "id": "jQATbpGyeByP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (load dataset)\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('winogrande', 'winogrande_xl')\n",
        "subset = dataset['validation'].shuffle(seed=42).select(range(100))\n",
        "print(subset)"
      ],
      "metadata": {
        "id": "s-Jkr97igAJO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472,
          "referenced_widgets": [
            "3bd1b87f896847db8f83ed72201fa7f2",
            "59331a137ac0426ea359f613fbd1ef40",
            "ca9701e60e564e82a469a0b36d44aad5",
            "6048bff6cefb4a59bf1b497506de93b2",
            "fa14fe9851e446139388ba815f5b0c6e",
            "4a4e465fad1f4fafb561b8a762beb85a",
            "3ad098ddc22848278c2b0b355ef108d8",
            "e06fcb4f953a49f687a4ecad8cdf7e04",
            "1ecbd6aa072c4826b2c7096e4e971ea0",
            "fc39a0f43d164ebc89bd878cc6b4623a",
            "bc87e20affbe4e68b2b885e8594f5ade",
            "1944206f60b74ba9a846c872e500049c",
            "1867b591db3c4903ab88275e29d351a0",
            "0595ef14256a495fb7d9e792c9737c8d",
            "20d5f1358efa4c9890497b55e8b81359",
            "e399a49b2ef2446ca036556131f80832",
            "8dc6ec946e874fe48166859ba5e54c37",
            "ebe01fc9343a455a9e97fcaed0761855",
            "8dad374dde144eab8de71125e3788678",
            "6a7cfd137f30415b98ba6ebc96fef540",
            "b0cee69f303249ce84903936ea313a63",
            "184bfd61357c4f1bbef3abee60a1bf68",
            "47fdba2732974c1f92b278ba7a715576",
            "944aad00f87140faa9135235c8ac75c0",
            "2aeace7d52454af7b0d08ddbc09b8d73",
            "a31e6f8e904649ec9b6b7c38486408b7",
            "30974b90bd674aa1b55007869f7078bf",
            "611c00cafaf946198d8b2713a45fd992",
            "6b9cd437fd4746858936a6acd99c7e10",
            "3129a821f1e946f881c2ec082dbca975",
            "dc13b2daa0f842dcbf677d2d84b6bd0b",
            "7ccf2a6e151c4c1ebb529f7105030f9c",
            "9f06badd34c74984a5bd7904f141f70a",
            "eaa400f4e9364332bccff9667740cf1e",
            "15f99c1ebb8c4bf89421894dff8c2f4d",
            "2f58b4a4890f4214b75e6c56ca10af15",
            "3bf1253995264fe1a098890cefb232c9",
            "a4981d2dfed94b088105f16c5f1bf699",
            "6dad2b0ae534471885cebd7082c65031",
            "5ffebca4b8814cc8a9c303e654dfbe1b",
            "7bcb953e8b96458a95af24aad7713250",
            "0e7a18b2d86a42f7915e08f9d35f09f0",
            "877d6faa9d4e4b3b912a669d274cbd0b",
            "609121b6a45f47d2bbe62216b97e8dd1",
            "08bcfcf5e2e34e2399b832efd3958a18",
            "74e9115a2eb34201b719ed91d40e025f",
            "4168b48ae537462682430db4e1f85e19",
            "65556d7209ff4bb589a2f210ac19074f",
            "1ce1d22d17804be4a14110e30a214bfa",
            "65546318887143b599ac1ae864262ea9",
            "a463d50079fd4d189e1c374cb54ee3d7",
            "16dbf2dcdb334ad288d8ea91ec4ed6b6",
            "6206b66297524775854a2e2081a3eec4",
            "96acb21040de4c858ffa36f9868088ec",
            "fb49dd1fbed145aeba82fb670b2aae29",
            "90716aa8b8f741bcb788697a9326fa63",
            "bbbf4ec02f2f4be1aa577bc78aca3399",
            "c4c630575e4747c0969e7dd67c7a6b52",
            "83964929a2db4e5ab3a0e1f87fb59c68",
            "831223a440444a13bc6ccccb244b4533",
            "d3b5335e8d8e4da4b28a6448bcf22aa7",
            "2dfd690c22294a13bfd9f23b836e4dba",
            "afbfec6f9dd0454dbeea301e00d0abd0",
            "a2b95adfdfd74c91aaf32c5b5f48c7a9",
            "2fa417cef9b049ebbced0faddab554ae",
            "12e9bab0fc864780a279b74b8b607ece"
          ]
        },
        "outputId": "88781148-b907-4cbb-9ee5-f404fbcc7d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/9.97k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bd1b87f896847db8f83ed72201fa7f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "winogrande.py:   0%|          | 0.00/5.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1944206f60b74ba9a846c872e500049c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.40M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47fdba2732974c1f92b278ba7a715576"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/40398 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaa400f4e9364332bccff9667740cf1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1767 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08bcfcf5e2e34e2399b832efd3958a18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1267 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90716aa8b8f741bcb788697a9326fa63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['sentence', 'option1', 'option2', 'answer'],\n",
            "    num_rows: 100\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 rows of subset\n",
        "features = ['sentence', 'option1', 'option2', 'answer']\n",
        "for i in range(5):\n",
        "    for key in features:\n",
        "        print(f\"{key}: {subset[key][i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT4IyqnGUPyX",
        "outputId": "e93751b9-6d4e-4b44-ea73-4ba16512694d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence: Patricia decided to buy Felicia dinner because they had been through a lot and _ just inherited some money.\n",
            "option1: Patricia\n",
            "option2: Felicia\n",
            "answer: 1\n",
            "sentence: The clothing in the north was warmer than the clothing in the south because there was more snow in the _ .\n",
            "option1: south\n",
            "option2: north\n",
            "answer: 2\n",
            "sentence: Timmy bought a transporter for his cat so he could take him on the plane but the _ was too small.\n",
            "option1: transporter\n",
            "option2: plane\n",
            "answer: 1\n",
            "sentence: It was easier for the diner to follow their budget than the food truck because the _ had more money to spend.\n",
            "option1: diner\n",
            "option2: food truck\n",
            "answer: 1\n",
            "sentence: John could not hear his alarm clock when he was sleeping with a headphone on his head because the _ is closer.\n",
            "option1: headphone\n",
            "option2: clock\n",
            "answer: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(subset['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gHH1UaLXAUu",
        "outputId": "e70e1fde-5c36-4c2d-f4bd-e294900d58e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '2', '1', '1', '1', '1', '2', '2', '1', '2', '1', '1', '2', '2', '1', '1', '1', '1', '1', '2', '2', '2', '1', '2', '2', '2', '2', '2', '2', '1', '2', '1', '2', '1', '1', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '2', '1', '1', '2', '1', '1', '1', '2', '2', '2', '1', '1', '2', '2', '2', '2', '2', '2', '1', '1', '2', '2', '2', '2', '1', '1', '1', '2', '1', '1', '1', '2', '2', '2', '1', '1', '2', '1', '1', '2', '1', '2', '2', '1', '2', '1', '1', '2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Με κατάλληλο [μετασχηματισμό](https://huggingface.co/DeepPavlov/roberta-large-winogrande) της παραπάνω εισόδου (πρόταση με κενό και δύο επιλογές συμπλήρωσης), καλείστε να καταγράψετε το accuracy σχετικών μοντέλων που επιλύουν το πρόβλημα, συγκρίνοντας το predicted label με το πραγματικό label (1: πρώτη επιλογή, 2: δεύτερη επιλογή). Ουσιαστικά θα πρέπει να αναγάγετε το παραπάνω πρόβλημα σε κάποιο πιο κλασικό πρόβλημα της επεξεργασίας φυσικής γλώσσας.\n",
        "\n",
        "Δοκιμάστε τουλάχιστον 3 κατάλληλα μοντέλα από το Huggingface για να προσεγγίσετε το πρόβλημα του Winogrande. Προτείνουμε τη χρήση pipelines για τη διευκόλυνσή σας."
      ],
      "metadata": {
        "id": "hpuR6PbVmwbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👁️👁️H χρήση NLI models με zero-shot-classification pipeline οπου το sequence είναι το sentence και τα 2 options είναι τα labels είναι κατάλληλο για το συγκεκριμένο dataset οπως θα δούμε απο τα accuracies παρακάτω και αυτό οφείλεται στο γεγονός ότι τα nli models έχουν logic and common sense cabapilities που τα χρειαζόμαστε σε αυτό το dataset."
      ],
      "metadata": {
        "id": "SC8dS3LVI71h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (load models)\n",
        "models = [\n",
        "    \"DeepPavlov/roberta-large-winogrande\",\n",
        "    \"sileod/deberta-v3-large-tasksource-nli\",\n",
        "    \"sileod/deberta-v3-base-tasksource-nli\"\n",
        "]"
      ],
      "metadata": {
        "id": "m1oZcCm2c29U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (create pipelines)\n",
        "from transformers import pipeline\n",
        "\n",
        "pipelines = [pipeline(\"zero-shot-classification\", models[0]),\n",
        "             pipeline(\"zero-shot-classification\", models[1]),\n",
        "             pipeline(\"zero-shot-classification\", models[2])\n",
        "]"
      ],
      "metadata": {
        "id": "9m6akMdBuFcw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "9776da1f6c3a41df8989ce34ff1c4847",
            "34bcbd6245fd4c67b50d7c73f90fd587",
            "f8299912affd44ec80b148930a033daa",
            "fa36899096244f4bb2db32af7d96b42e",
            "18071d794b7743878627d39dced27289",
            "4be38544b7014df4ad543ba40fd308fd",
            "a7b31e532a9d418f862c47da70c8fee7",
            "46edede6ece7439782486103a539ba28",
            "fa24e5978c3744cea9eec4029f2340bc",
            "b8b02b9798f7460e890401fdfe00303a",
            "292678d9bfc84b84b20325745619fe96",
            "858888d5133c470c8ec3d06ad076ec39",
            "23381e3ec25249b380d8661841c820a6",
            "f1fdc88bffb44242aab0382a4d10de68",
            "92e593880b1247149816cce957919bc9",
            "790e53d6160a49109a05afc6250ee943",
            "3d5e5442e2704b87a5ae12ae11b376fe",
            "a6a73537ebb34501a86bd2132712f453",
            "adf5c8cf611a47edb1205aaf1a8e64fa",
            "efc12bcbac234bd1970bf79ffe981244",
            "2f5044c906c34a0c9f5065e7c8019162",
            "1907dbf40cfe48f898bcecd393bc0e68",
            "371a9b4be4c64bbeb9e49a3c53ae34fa",
            "7dfe7f744dda49d7b0305628a20739d7",
            "ee6a318ff0c04eba91efb842c5f8d3ae",
            "b5be25327e0e4f33a7f03d322a18d081",
            "f5d69adb0aec462abafeed0d526dd643",
            "106b6fe11a05489e84aff67bf6617e00",
            "9c1480f69ae04185ae679cdadb380c22",
            "07f47bc8a9aa44368f3988aef38400d3",
            "2eadcd85318a4396868980afcbe00087",
            "21fb3054f14a4d08ad8e61b1a9d0eba8",
            "4f96960466eb45e0b67663f787a82d2d",
            "644241b3c8de49d0951f9f94ae9853c3",
            "9cda395ceb02477682093dd251b29905",
            "c876adb01c9144d3a0f61e9902252152",
            "3609b4d2549d47efa7a5177fce009d95",
            "8242ef9adb7f47c6a373c118db3353c4",
            "5a8f904e80914fe48fba2f6eaaf4af16",
            "9ef3416a382e4d81916aeb3083c37ac6",
            "badd4536eeda40349fc4dabe2a5ae55f",
            "3322bee8d47146e0af2530d45940624f",
            "3f5d4bad065e4e759b2554df6b0b401e",
            "8ad51d8552c147dc997710ac3d06a218",
            "1981232cfa3642fa9afaf388cf8bb153",
            "ed1a716feb9d4f93ac9d968e70dd155a",
            "bbdba0533fb54ff4bbaf1adf0fcfb5c8",
            "89b2491fa1c84d82a8a8ce6bc8be68ef",
            "7d93169d8d0e47a6ae8829812b2bd901",
            "7a61b1051c0a41419d0b338865f66156",
            "d363d845712a40dca8907fd03a90f0ec",
            "45180a025cba440c899b26d3c33d8cb4",
            "84f48d6c6a88469f8b6e47c7e5b4138d",
            "80772f9ff9594a6682e6c29a5f6d695e",
            "6325787ba5f34054a8e4b877fc994632",
            "cde9ce91a04a42dca702dcc5ac8eaa2e",
            "e79d230599454674b3a822e3996b06d2",
            "e773b43837e342a9beadd69d1494a8ad",
            "665519c2241e4a62a2b5547468d81d2d",
            "94e85505d0ba48a4a474557e6f0ea72c",
            "f947526e96464c00b0a2cd281fe78fab",
            "252a2cf5159845af919b676f962a45b9",
            "c590a619ba9b4ea0b8aeeda3027b1f5f",
            "3eb7287a2d694020865b39bcdbb6ad04",
            "297036b9c33c42e98f61f74f69c2f36c",
            "14e71bbc42fd4e01920bd3ac2e1b66d1",
            "ff6709a744974412aa929cbffac1bd73",
            "a678bb5283ee4b14b891f6556e94bfe6",
            "cd349ac92f994741a43d6abc4890a14e",
            "97c833ba75e64df19901ca94c431dcd0",
            "754749aec3774aa886198bb23423e875",
            "42c1a21630094f9e86d091ff9d1ac738",
            "6021283e36874360be06734021cc167f",
            "3db65c7ac25146c6abcd170c0fb265cf",
            "dd36d426f1c141aca7c4f45297380189",
            "11fe42afc6d84343b43b5abf77770b96",
            "c4c2fd1305b34ced9d1158aadaba2eb7"
          ]
        },
        "outputId": "75a4e0a0-0d80-4502-e2f6-5a2f49ae0964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/18.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9776da1f6c3a41df8989ce34ff1c4847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "858888d5133c470c8ec3d06ad076ec39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "371a9b4be4c64bbeb9e49a3c53ae34fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "644241b3c8de49d0951f9f94ae9853c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1981232cfa3642fa9afaf388cf8bb153"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cde9ce91a04a42dca702dcc5ac8eaa2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff6709a744974412aa929cbffac1bd73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here (function for predicting best fill)\n",
        "from tqdm import tqdm\n",
        "\n",
        "def make_predictions(pipeline, model_name):\n",
        "  print(f\"\\nEvaluating: {model_name}\")\n",
        "\n",
        "  correct = 0\n",
        "\n",
        "  for example in tqdm(subset):\n",
        "      options = [example['option1'], example['option2']]\n",
        "      result = pipeline(example['sentence'], options)\n",
        "\n",
        "      # Convert the answer to an integer\n",
        "      answer_index = int(example['answer']) - 1\n",
        "\n",
        "      if result['labels'][0] == options[answer_index]:  # labels are sorted on descending order based on score\n",
        "          correct += 1\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = correct / len(subset)\n",
        "  print()\n",
        "  print(\"Accuracy is: \", accuracy)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "PR6sz6xug_7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions(pipelines[0], \"roberta-large-winogrande\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIbm8iHWdzUy",
        "outputId": "cefed69d-a35a-4e1c-89ca-c4a6bb001cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating: roberta-large-winogrande\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:51<00:00,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'Playing basketball came easier for Cynthia than Jennifer but _ had more control of their body movements.', 'labels': ['Jennifer', 'Cynthia'], 'scores': [0.9831526875495911, 0.016847368329763412]}\n",
            "\n",
            "Accuracy is:  0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.76"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions(pipelines[1], \"deberta-v3-large-tasksource-nli\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvgBDkINdzZ4",
        "outputId": "39ad408d-fd4a-48c2-d9e2-94bd1e55cdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating: deberta-v3-large-tasksource-nli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 100/100 [06:14<00:00,  3.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy is:  0.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions(pipelines[2], \"deberta-v3-base-tasksource-nli\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLSQO2IUdzeA",
        "outputId": "02163df7-51a1-40f3-f2db-159cad590397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating: deberta-v3-base-tasksource-nli\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 100/100 [01:30<00:00,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy is:  0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.71"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Άρα η χρήση NLI models με zero-shot-classification pipeline μας οδήγησε σε αρκετά ικανοποιητικά accuracies χωρίς καθόλου fine tuning."
      ],
      "metadata": {
        "id": "V_5ALF9eHxck"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y2UxEv7x1Zj1"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
